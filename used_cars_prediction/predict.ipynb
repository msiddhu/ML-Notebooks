{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type',\n",
      "       'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = pd.read_excel ('data_train.xlsx')\n",
    "test=pd.read_excel('data_test.xlsx')\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6019.000000</td>\n",
       "      <td>6.019000e+03</td>\n",
       "      <td>5977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013.358199</td>\n",
       "      <td>5.873838e+04</td>\n",
       "      <td>5.278735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.269742</td>\n",
       "      <td>9.126884e+04</td>\n",
       "      <td>0.808840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.710000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>3.400000e+04</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>5.300000e+04</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>7.300000e+04</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>6.500000e+06</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year  Kilometers_Driven        Seats\n",
       "count  6019.000000       6.019000e+03  5977.000000\n",
       "mean   2013.358199       5.873838e+04     5.278735\n",
       "std       3.269742       9.126884e+04     0.808840\n",
       "min    1998.000000       1.710000e+02     0.000000\n",
       "25%    2011.000000       3.400000e+04     5.000000\n",
       "50%    2014.000000       5.300000e+04     5.000000\n",
       "75%    2016.000000       7.300000e+04     5.000000\n",
       "max    2019.000000       6.500000e+06    10.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.pop('Price')\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x['Name'] = x.Name.str.split().str.get(0)\n",
    "test['Name'] = test.Name.str.split().str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  0\n",
       "Location              0\n",
       "Year                  0\n",
       "Kilometers_Driven     0\n",
       "Fuel_Type             0\n",
       "Transmission          0\n",
       "Owner_Type            0\n",
       "Mileage               2\n",
       "Engine               36\n",
       "Power                36\n",
       "Seats                42\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Seats'].fillna(x['Seats'].mean(),inplace=True)\n",
    "test['Seats'].fillna(test['Seats'].mean(),inplace=True)\n",
    "data = pd.concat([x,test], sort=False)\n",
    "x['Mileage'] = x['Mileage'].fillna('17.0 kmpl')\n",
    "test['Mileage'] = test['Mileage'].fillna('17.0 kmpl')\n",
    "x['Mileage'] = x['Mileage'].replace(\"0.0 kmpl\", \"17.0 kmpl\")\n",
    "test['Mileage'] = test['Mileage'].replace(\"0.0 kmpl\", \"17.0 kmpl\")\n",
    "x['Engine'] = x['Engine'].fillna('1197 CC')\n",
    "test['Engine'] = test['Engine'].fillna('1197 CC')\n",
    "x['Power'] = x['Power'].fillna('74 bhp')\n",
    "test['Power'] = test['Power'].fillna('74 bhp')\n",
    "x['Power'] = x['Power'].replace(\"null bhp\", \"74 bhp\")\n",
    "test['Power'] = test['Power'].replace(\"null bhp\", \"74 bhp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type',\n",
      "       'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats'],\n",
      "      dtype='object')\n",
      "Name                 0\n",
      "Location             0\n",
      "Year                 0\n",
      "Kilometers_Driven    0\n",
      "Fuel_Type            0\n",
      "Transmission         0\n",
      "Owner_Type           0\n",
      "Mileage              0\n",
      "Engine               0\n",
      "Power                0\n",
      "Seats                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.columns)\n",
    "print(x.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maruti' 'Hyundai' 'Honda' 'Audi' 'Nissan' 'Toyota' 'Volkswagen' 'Tata'\n",
      " 'Land' 'Mitsubishi' 'Renault' 'Mercedes-Benz' 'BMW' 'Mahindra' 'Ford'\n",
      " 'Porsche' 'Datsun' 'Jaguar' 'Volvo' 'Chevrolet' 'Skoda' 'Mini' 'Fiat'\n",
      " 'Jeep' 'Smart' 'Ambassador' 'Isuzu' 'ISUZU' 'Force' 'Bentley'\n",
      " 'Lamborghini']\n",
      "['CNG' 'Diesel' 'Petrol' 'LPG' 'Electric']\n",
      "['Manual' 'Automatic']\n",
      "['First' 'Second' 'Fourth & Above' 'Third']\n",
      "['Mumbai' 'Pune' 'Chennai' 'Coimbatore' 'Hyderabad' 'Jaipur' 'Kochi'\n",
      " 'Kolkata' 'Delhi' 'Bangalore' 'Ahmedabad']\n"
     ]
    }
   ],
   "source": [
    "print(x.Name.unique())\n",
    "print(x.Fuel_Type.unique())\n",
    "print(x.Transmission.unique())\n",
    "print(x.Owner_Type.unique())\n",
    "print(x.Location.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type',\n",
      "       'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6019 entries, 0 to 6018\n",
      "Data columns (total 11 columns):\n",
      "Name                 6019 non-null object\n",
      "Location             6019 non-null object\n",
      "Year                 6019 non-null int64\n",
      "Kilometers_Driven    6019 non-null int64\n",
      "Fuel_Type            6019 non-null object\n",
      "Transmission         6019 non-null object\n",
      "Owner_Type           6019 non-null object\n",
      "Mileage              6019 non-null object\n",
      "Engine               6019 non-null object\n",
      "Power                6019 non-null object\n",
      "Seats                6019 non-null float64\n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 517.3+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_number(name):\n",
    "    title_search = re.search('([\\d+\\.+\\d]+\\W)', name)\n",
    "    5\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "x['Mileage'] = x['Mileage'].apply(get_number).astype('float')\n",
    "x['Engine'] = x['Engine'].apply(get_number).astype('int')\n",
    "x['Power'] = x['Power'].apply(get_number).astype('float')\n",
    "\n",
    "test['Mileage'] = test['Mileage'].apply(get_number).astype('float')\n",
    "test['Engine'] = test['Engine'].apply(get_number).astype('int')\n",
    "test['Power'] = test['Power'].apply(get_number).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6019 entries, 0 to 6018\n",
      "Data columns (total 11 columns):\n",
      "Name                 6019 non-null object\n",
      "Location             6019 non-null object\n",
      "Year                 6019 non-null int64\n",
      "Kilometers_Driven    6019 non-null int64\n",
      "Fuel_Type            6019 non-null object\n",
      "Transmission         6019 non-null object\n",
      "Owner_Type           6019 non-null object\n",
      "Mileage              6019 non-null float64\n",
      "Engine               6019 non-null int32\n",
      "Power                6019 non-null float64\n",
      "Seats                6019 non-null float64\n",
      "dtypes: float64(3), int32(1), int64(2), object(5)\n",
      "memory usage: 493.8+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "x['Name'] = label_encoder.fit_transform(x['Name'])\n",
    "x['Location'] = label_encoder.fit_transform(x['Location'])\n",
    "x['Fuel_Type'] = label_encoder.fit_transform(x['Fuel_Type'])\n",
    "x['Transmission'] = label_encoder.fit_transform(x['Transmission'])\n",
    "x['Owner_Type'] = label_encoder.fit_transform(x['Owner_Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6019 entries, 0 to 6018\n",
      "Data columns (total 11 columns):\n",
      "Name                 6019 non-null int32\n",
      "Location             6019 non-null int32\n",
      "Year                 6019 non-null int64\n",
      "Kilometers_Driven    6019 non-null int64\n",
      "Fuel_Type            6019 non-null int32\n",
      "Transmission         6019 non-null int32\n",
      "Owner_Type           6019 non-null int32\n",
      "Mileage              6019 non-null float64\n",
      "Engine               6019 non-null int32\n",
      "Power                6019 non-null float64\n",
      "Seats                6019 non-null float64\n",
      "dtypes: float64(3), int32(6), int64(2)\n",
      "memory usage: 376.3 KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4815 entries, 3509 to 2732\n",
      "Data columns (total 11 columns):\n",
      "Name                 4815 non-null int32\n",
      "Location             4815 non-null int32\n",
      "Year                 4815 non-null int64\n",
      "Kilometers_Driven    4815 non-null int64\n",
      "Fuel_Type            4815 non-null int32\n",
      "Transmission         4815 non-null int32\n",
      "Owner_Type           4815 non-null int32\n",
      "Mileage              4815 non-null float64\n",
      "Engine               4815 non-null int32\n",
      "Power                4815 non-null float64\n",
      "Seats                4815 non-null float64\n",
      "dtypes: float64(3), int32(6), int64(2)\n",
      "memory usage: 338.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power</th>\n",
       "      <th>Seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>24153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22.54</td>\n",
       "      <td>1396</td>\n",
       "      <td>88.73</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.21</td>\n",
       "      <td>1493</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>92000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1405</td>\n",
       "      <td>70.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>62000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.80</td>\n",
       "      <td>1248</td>\n",
       "      <td>75.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>31000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.68</td>\n",
       "      <td>2393</td>\n",
       "      <td>147.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Location  Year  Kilometers_Driven  Fuel_Type  Transmission  \\\n",
       "3509    10         3  2017              24153          1             1   \n",
       "3332    17         9  2013              35000          1             1   \n",
       "5383    27         5  2005              92000          1             1   \n",
       "1891    18         4  2014              62000          1             1   \n",
       "5757    28         8  2017              31000          1             1   \n",
       "\n",
       "      Owner_Type  Mileage  Engine   Power  Seats  \n",
       "3509           2    22.54    1396   88.73    5.0  \n",
       "3332           0    17.21    1493  100.00    7.0  \n",
       "5383           2    16.10    1405   70.00    5.0  \n",
       "1891           0    17.80    1248   75.00    5.0  \n",
       "5757           0    13.68    2393  147.80    7.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(X_train.keys())]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,993\n",
      "Trainable params: 4,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3852 samples, validate on 963 samples\n",
      "Epoch 1/1000\n",
      "3852/3852 [==============================] - 0s 60us/step - loss: 9588325.3383 - mae: 452.7654 - mse: 9588328.0000 - val_loss: 1958.1527 - val_mae: 40.4289 - val_mse: 1958.1530\n",
      "Epoch 2/1000\n",
      "3852/3852 [==============================] - 0s 47us/step - loss: 3068204.7725 - mae: 513.9628 - mse: 3068205.7500 - val_loss: 1396092.0084 - val_mae: 1043.1389 - val_mse: 1396092.1250\n",
      "Epoch 3/1000\n",
      "3852/3852 [==============================] - 0s 42us/step - loss: 653522.8796 - mae: 387.6434 - mse: 653523.0000 - val_loss: 4314.9918 - val_mae: 50.2675 - val_mse: 4314.9917\n",
      "Epoch 4/1000\n",
      "3852/3852 [==============================] - 0s 50us/step - loss: 427580.4953 - mae: 260.9801 - mse: 427580.3750 - val_loss: 1486.0352 - val_mae: 31.8495 - val_mse: 1486.0350\n",
      "Epoch 5/1000\n",
      "3852/3852 [==============================] - 0s 44us/step - loss: 1074186.5983 - mae: 376.8007 - mse: 1074186.6250 - val_loss: 69473.1674 - val_mae: 226.3296 - val_mse: 69473.1719\n",
      "Epoch 6/1000\n",
      "3852/3852 [==============================] - 0s 46us/step - loss: 1366272.5054 - mae: 458.2981 - mse: 1366272.5000 - val_loss: 24184.8114 - val_mae: 125.0322 - val_mse: 24184.8105\n",
      "Epoch 7/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 1232156.6740 - mae: 423.0423 - mse: 1232157.0000 - val_loss: 236.2493 - val_mae: 8.6952 - val_mse: 236.2494\n",
      "Epoch 8/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 775869.3180 - mae: 337.6650 - mse: 775869.1875 - val_loss: 1389603.6625 - val_mae: 998.6054 - val_mse: 1389603.6250\n",
      "Epoch 9/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 3362897.3069 - mae: 697.3168 - mse: 3362897.5000 - val_loss: 28134.4409 - val_mae: 127.0783 - val_mse: 28134.4453\n",
      "Epoch 10/1000\n",
      "3852/3852 [==============================] - 0s 48us/step - loss: 986041.9423 - mae: 371.1225 - mse: 986041.5625 - val_loss: 4486.8694 - val_mae: 51.0178 - val_mse: 4486.8701\n",
      "Epoch 11/1000\n",
      "3852/3852 [==============================] - 0s 47us/step - loss: 683638.7421 - mae: 356.5421 - mse: 683638.7500 - val_loss: 319320.3014 - val_mae: 492.2501 - val_mse: 319320.3438\n",
      "Epoch 12/1000\n",
      "3852/3852 [==============================] - 0s 47us/step - loss: 1775669.3482 - mae: 516.9290 - mse: 1775669.0000 - val_loss: 129979.2796 - val_mae: 282.6547 - val_mse: 129979.2734\n",
      "Epoch 13/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 1749220.7307 - mae: 528.8736 - mse: 1749220.1250 - val_loss: 3967.1578 - val_mae: 52.0561 - val_mse: 3967.1582\n",
      "Epoch 14/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 501470.8390 - mae: 308.0814 - mse: 501470.7500 - val_loss: 82064.5659 - val_mae: 264.4540 - val_mse: 82064.5703\n",
      "Epoch 15/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 711831.9974 - mae: 432.7529 - mse: 711832.0000 - val_loss: 38971.9279 - val_mae: 141.3700 - val_mse: 38971.9297\n",
      "Epoch 16/1000\n",
      "3852/3852 [==============================] - 0s 42us/step - loss: 820082.4885 - mae: 280.7291 - mse: 820082.5000 - val_loss: 1342.6651 - val_mae: 31.3693 - val_mse: 1342.6652\n",
      "Epoch 17/1000\n",
      "3852/3852 [==============================] - 0s 46us/step - loss: 2664233.6035 - mae: 359.4676 - mse: 2664233.5000 - val_loss: 37571.3497 - val_mae: 148.4689 - val_mse: 37571.3477\n",
      "Epoch 18/1000\n",
      "3852/3852 [==============================] - 0s 47us/step - loss: 220256.5835 - mae: 181.9061 - mse: 220256.5938 - val_loss: 35419.9123 - val_mae: 141.7654 - val_mse: 35419.9141\n",
      "Epoch 19/1000\n",
      "3852/3852 [==============================] - 0s 51us/step - loss: 344935.9386 - mae: 294.3089 - mse: 344935.9688 - val_loss: 425109.9857 - val_mae: 534.2493 - val_mse: 425110.0312\n",
      "Epoch 20/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 613342.9265 - mae: 320.5876 - mse: 613342.6875 - val_loss: 766.6658 - val_mae: 21.3234 - val_mse: 766.6658\n",
      "Epoch 21/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 175167.7500 - mae: 197.8171 - mse: 175167.7500 - val_loss: 4760.8305 - val_mae: 65.9900 - val_mse: 4760.8301\n",
      "Epoch 22/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 195923.9373 - mae: 227.7655 - mse: 195923.9531 - val_loss: 19022.6039 - val_mae: 126.1126 - val_mse: 19022.6055\n",
      "Epoch 23/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 736044.2436 - mae: 298.3036 - mse: 736044.3750 - val_loss: 1886.6075 - val_mae: 30.1462 - val_mse: 1886.6078\n",
      "Epoch 24/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 213548.6697 - mae: 188.4543 - mse: 213548.7031 - val_loss: 21873.4196 - val_mae: 121.0281 - val_mse: 21873.4180\n",
      "Epoch 25/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 673621.4517 - mae: 260.5354 - mse: 673621.3750 - val_loss: 5155.7576 - val_mae: 63.4748 - val_mse: 5155.7568\n",
      "Epoch 26/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 137013.0577 - mae: 178.6921 - mse: 137013.0469 - val_loss: 3805.2819 - val_mae: 53.4368 - val_mse: 3805.2820\n",
      "Epoch 27/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 163727.9898 - mae: 196.2519 - mse: 163728.0312 - val_loss: 13674.8982 - val_mae: 79.1411 - val_mse: 13674.8994\n",
      "Epoch 28/1000\n",
      "3852/3852 [==============================] - 0s 44us/step - loss: 486378.2536 - mae: 244.9796 - mse: 486378.2812 - val_loss: 4941.7324 - val_mae: 52.1889 - val_mse: 4941.7324\n",
      "Epoch 29/1000\n",
      "3852/3852 [==============================] - 0s 42us/step - loss: 400697.2404 - mae: 119.2289 - mse: 400697.2188 - val_loss: 832896.3043 - val_mae: 776.5798 - val_mse: 832896.1875\n",
      "Epoch 30/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 312024.3754 - mae: 257.1971 - mse: 312024.3750 - val_loss: 13850.0164 - val_mae: 90.4325 - val_mse: 13850.0156\n",
      "Epoch 31/1000\n",
      "3852/3852 [==============================] - 0s 44us/step - loss: 83007.7046 - mae: 142.1743 - mse: 83007.7188 - val_loss: 106994.0444 - val_mae: 278.1566 - val_mse: 106994.0469\n",
      "Epoch 32/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 132576.4503 - mae: 140.8508 - mse: 132576.4688 - val_loss: 1237.9223 - val_mae: 27.9589 - val_mse: 1237.9224\n",
      "Epoch 33/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 65099.6552 - mae: 134.8301 - mse: 65099.6562 - val_loss: 316.4620 - val_mae: 14.0666 - val_mse: 316.4619\n",
      "Epoch 34/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 206612.7891 - mae: 118.6303 - mse: 206612.7812 - val_loss: 22491.7613 - val_mae: 125.5089 - val_mse: 22491.7598\n",
      "Epoch 35/1000\n",
      "3852/3852 [==============================] - 0s 42us/step - loss: 103362.9597 - mae: 153.6379 - mse: 103362.9688 - val_loss: 3821.8091 - val_mae: 53.9712 - val_mse: 3821.8098\n",
      "Epoch 36/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 250027.0255 - mae: 115.6220 - mse: 250027.0938 - val_loss: 5540.8234 - val_mae: 66.9264 - val_mse: 5540.8242\n",
      "Epoch 37/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 452620.7905 - mae: 120.2213 - mse: 452620.7812 - val_loss: 2388.4831 - val_mae: 44.5127 - val_mse: 2388.4829\n",
      "Epoch 38/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 66515.9431 - mae: 135.5031 - mse: 66515.9297 - val_loss: 2316.5722 - val_mae: 29.3508 - val_mse: 2316.5723\n",
      "Epoch 39/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 136687.8332 - mae: 164.8009 - mse: 136687.8438 - val_loss: 3821.2696 - val_mae: 39.1856 - val_mse: 3821.2695\n",
      "Epoch 40/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 70198.0958 - mae: 111.7309 - mse: 70198.0938 - val_loss: 1656.1987 - val_mae: 29.3107 - val_mse: 1656.1990\n",
      "Epoch 41/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 88323.9463 - mae: 126.8002 - mse: 88323.9297 - val_loss: 45627.0905 - val_mae: 186.6263 - val_mse: 45627.0977\n",
      "Epoch 42/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 195324.0698 - mae: 166.2210 - mse: 195324.0938 - val_loss: 824.1729 - val_mae: 15.5043 - val_mse: 824.1729\n",
      "Epoch 43/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 354512.1447 - mae: 169.1105 - mse: 354512.1875 - val_loss: 2897.1903 - val_mae: 39.2957 - val_mse: 2897.1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 92475.4565 - mae: 126.4383 - mse: 92475.4531 - val_loss: 232645.4072 - val_mae: 426.4183 - val_mse: 232645.3906\n",
      "Epoch 45/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 139041.8433 - mae: 160.3124 - mse: 139041.8750 - val_loss: 4280.5768 - val_mae: 51.4629 - val_mse: 4280.5767\n",
      "Epoch 46/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 58972.0128 - mae: 122.8606 - mse: 58972.0000 - val_loss: 2591.1632 - val_mae: 41.8059 - val_mse: 2591.1631\n",
      "Epoch 47/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 201365.4392 - mae: 170.9611 - mse: 201365.4688 - val_loss: 16423.8186 - val_mae: 108.6781 - val_mse: 16423.8184\n",
      "Epoch 48/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 102371.7171 - mae: 144.9473 - mse: 102371.7266 - val_loss: 6583.5744 - val_mae: 65.0491 - val_mse: 6583.5752\n",
      "Epoch 49/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 132395.5726 - mae: 151.4679 - mse: 132395.5469 - val_loss: 9464.1528 - val_mae: 87.9811 - val_mse: 9464.1533\n",
      "Epoch 50/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 49044.7481 - mae: 104.9140 - mse: 49044.7461 - val_loss: 10230.1520 - val_mae: 91.3028 - val_mse: 10230.1514\n",
      "Epoch 51/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 34618.2687 - mae: 98.5059 - mse: 34618.2578 - val_loss: 18837.9503 - val_mae: 112.2852 - val_mse: 18837.9473\n",
      "Epoch 52/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46997.3803 - mae: 102.2292 - mse: 46997.3984 - val_loss: 49244.4434 - val_mae: 195.7991 - val_mse: 49244.4531\n",
      "Epoch 53/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46833.2390 - mae: 103.1419 - mse: 46833.2383 - val_loss: 986.2868 - val_mae: 29.5330 - val_mse: 986.2868\n",
      "Epoch 54/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40989.3812 - mae: 106.4003 - mse: 40989.3789 - val_loss: 768.4339 - val_mae: 22.9918 - val_mse: 768.4338\n",
      "Epoch 55/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 27986.4826 - mae: 83.1156 - mse: 27986.4805 - val_loss: 48154.4573 - val_mae: 192.6477 - val_mse: 48154.4492\n",
      "Epoch 56/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 142673.3481 - mae: 97.3156 - mse: 142673.4062 - val_loss: 8201.8006 - val_mae: 74.3465 - val_mse: 8201.7998\n",
      "Epoch 57/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 125782.5774 - mae: 91.4543 - mse: 125782.5781 - val_loss: 5607.8676 - val_mae: 55.8630 - val_mse: 5607.8672\n",
      "Epoch 58/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 46872.0687 - mae: 80.6513 - mse: 46872.0742 - val_loss: 1919.8426 - val_mae: 31.6514 - val_mse: 1919.8428\n",
      "Epoch 59/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 18506.8098 - mae: 61.0849 - mse: 18506.8105 - val_loss: 1843.6395 - val_mae: 32.9308 - val_mse: 1843.6395\n",
      "Epoch 60/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 10096.7582 - mae: 66.3027 - mse: 10096.7578 - val_loss: 58956.4556 - val_mae: 218.9283 - val_mse: 58956.4570\n",
      "Epoch 61/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 12900.0162 - mae: 49.7471 - mse: 12900.0166 - val_loss: 727.3666 - val_mae: 17.2565 - val_mse: 727.3665\n",
      "Epoch 62/1000\n",
      "3852/3852 [==============================] - 0s 41us/step - loss: 7732.2868 - mae: 46.5983 - mse: 7732.2861 - val_loss: 1636.6835 - val_mae: 36.1813 - val_mse: 1636.6837\n",
      "Epoch 63/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 19209.6699 - mae: 51.8656 - mse: 19209.6699 - val_loss: 7072.0434 - val_mae: 80.4125 - val_mse: 7072.0435\n",
      "Epoch 64/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 6042.2007 - mae: 45.7902 - mse: 6042.2017 - val_loss: 953.5769 - val_mae: 19.1124 - val_mse: 953.5769\n",
      "Epoch 65/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 4285.0694 - mae: 40.7629 - mse: 4285.0688 - val_loss: 1002.3855 - val_mae: 26.6903 - val_mse: 1002.3856\n",
      "Epoch 66/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 6256.6601 - mae: 33.9779 - mse: 6256.6592 - val_loss: 924.1823 - val_mae: 24.0965 - val_mse: 924.1824\n",
      "Epoch 67/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 4611.4891 - mae: 28.3653 - mse: 4611.4897 - val_loss: 6132.5538 - val_mae: 68.9018 - val_mse: 6132.5547\n",
      "Epoch 68/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 5610.3933 - mae: 30.6389 - mse: 5610.3936 - val_loss: 1401.1347 - val_mae: 33.5973 - val_mse: 1401.1348\n",
      "Epoch 69/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 13948.0517 - mae: 29.1885 - mse: 13948.0527 - val_loss: 75.3745 - val_mae: 6.2181 - val_mse: 75.3745\n",
      "Epoch 70/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 1782.0285 - mae: 24.0350 - mse: 1782.0288 - val_loss: 919.9348 - val_mae: 28.5853 - val_mse: 919.9348\n",
      "Epoch 71/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 429.6870 - mae: 15.7431 - mse: 429.6871 - val_loss: 59.0828 - val_mae: 4.8692 - val_mse: 59.0828\n",
      "Epoch 72/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 120.0736 - mae: 7.4772 - mse: 120.0736 - val_loss: 79.8858 - val_mae: 6.8232 - val_mse: 79.8858\n",
      "Epoch 73/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 74.9601 - mae: 5.4542 - mse: 74.9601 - val_loss: 49.3115 - val_mae: 4.5568 - val_mse: 49.3115\n",
      "Epoch 74/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 70.8983 - mae: 5.2832 - mse: 70.8983 - val_loss: 46.9943 - val_mae: 4.3916 - val_mse: 46.9943\n",
      "Epoch 75/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 66.9366 - mae: 5.0706 - mse: 66.9366 - val_loss: 92.9852 - val_mae: 7.5915 - val_mse: 92.9852\n",
      "Epoch 76/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 66.2457 - mae: 5.1049 - mse: 66.2457 - val_loss: 42.9406 - val_mae: 4.1778 - val_mse: 42.9406\n",
      "Epoch 77/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 67.3069 - mae: 5.0798 - mse: 67.3070 - val_loss: 68.9910 - val_mae: 4.9688 - val_mse: 68.9910\n",
      "Epoch 78/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 66.1904 - mae: 4.8928 - mse: 66.1904 - val_loss: 74.4775 - val_mae: 5.4512 - val_mse: 74.4775\n",
      "Epoch 79/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 63.3893 - mae: 4.8103 - mse: 63.3893 - val_loss: 67.1374 - val_mae: 5.5568 - val_mse: 67.1374\n",
      "Epoch 80/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 63.0850 - mae: 4.8076 - mse: 63.0850 - val_loss: 48.9793 - val_mae: 4.1091 - val_mse: 48.9793\n",
      "Epoch 81/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 60.5474 - mae: 4.7180 - mse: 60.5474 - val_loss: 45.3481 - val_mae: 3.9861 - val_mse: 45.3481\n",
      "Epoch 82/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 70.7886 - mae: 4.6342 - mse: 70.7886 - val_loss: 43.5377 - val_mae: 3.9354 - val_mse: 43.5377\n",
      "Epoch 83/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 58.9062 - mae: 4.6541 - mse: 58.9062 - val_loss: 54.2358 - val_mae: 4.2547 - val_mse: 54.2358\n",
      "Epoch 84/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 70.2706 - mae: 4.6827 - mse: 70.2706 - val_loss: 43.3416 - val_mae: 4.0308 - val_mse: 43.3416\n",
      "Epoch 85/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 59.7763 - mae: 4.6651 - mse: 59.7762 - val_loss: 58.5925 - val_mae: 4.7387 - val_mse: 58.5925\n",
      "Epoch 86/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 58.3051 - mae: 4.5754 - mse: 58.3051 - val_loss: 48.6878 - val_mae: 4.7302 - val_mse: 48.6878\n",
      "Epoch 87/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 56.2854 - mae: 4.5647 - mse: 56.2854 - val_loss: 44.6531 - val_mae: 4.3968 - val_mse: 44.6531\n",
      "Epoch 88/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 56.1199 - mae: 4.4518 - mse: 56.1199 - val_loss: 84.9335 - val_mae: 6.9353 - val_mse: 84.9335\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852/3852 [==============================] - 0s 34us/step - loss: 54.4377 - mae: 4.5473 - mse: 54.4377 - val_loss: 139.9242 - val_mae: 9.9213 - val_mse: 139.9242\n",
      "Epoch 90/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 56.7151 - mae: 4.4222 - mse: 56.7151 - val_loss: 42.6168 - val_mae: 4.0204 - val_mse: 42.6168\n",
      "Epoch 91/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 55.7396 - mae: 4.4293 - mse: 55.7396 - val_loss: 47.1753 - val_mae: 4.6557 - val_mse: 47.1753\n",
      "Epoch 92/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 69.1220 - mae: 4.3824 - mse: 69.1220 - val_loss: 45.2389 - val_mae: 4.1205 - val_mse: 45.2389\n",
      "Epoch 93/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 56.5104 - mae: 4.4456 - mse: 56.5104 - val_loss: 43.1336 - val_mae: 4.1318 - val_mse: 43.1336\n",
      "Epoch 94/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 55.0462 - mae: 4.4310 - mse: 55.0462 - val_loss: 61.3390 - val_mae: 4.6353 - val_mse: 61.3390\n",
      "Epoch 95/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 55.2961 - mae: 4.3369 - mse: 55.2961 - val_loss: 49.3795 - val_mae: 4.4457 - val_mse: 49.3795\n",
      "Epoch 96/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 55.1793 - mae: 4.3292 - mse: 55.1793 - val_loss: 44.0738 - val_mae: 3.9740 - val_mse: 44.0737\n",
      "Epoch 97/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 54.5992 - mae: 4.2650 - mse: 54.5992 - val_loss: 43.4903 - val_mae: 4.0330 - val_mse: 43.4903\n",
      "Epoch 98/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 52.7884 - mae: 4.2090 - mse: 52.7884 - val_loss: 65.9291 - val_mae: 4.7783 - val_mse: 65.9291\n",
      "Epoch 99/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 52.2200 - mae: 4.1449 - mse: 52.2200 - val_loss: 45.8517 - val_mae: 3.9880 - val_mse: 45.8517\n",
      "Epoch 100/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 53.5908 - mae: 4.1969 - mse: 53.5908 - val_loss: 41.0869 - val_mae: 4.0041 - val_mse: 41.0869\n",
      "Epoch 101/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 51.5657 - mae: 4.1376 - mse: 51.5657 - val_loss: 45.1189 - val_mae: 3.8112 - val_mse: 45.1189\n",
      "Epoch 102/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 52.5692 - mae: 4.1216 - mse: 52.5692 - val_loss: 44.2663 - val_mae: 4.1993 - val_mse: 44.2663\n",
      "Epoch 103/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 51.9417 - mae: 4.0591 - mse: 51.9417 - val_loss: 44.2679 - val_mae: 3.9091 - val_mse: 44.2679\n",
      "Epoch 104/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 50.3911 - mae: 3.9974 - mse: 50.3911 - val_loss: 54.2787 - val_mae: 4.4980 - val_mse: 54.2787\n",
      "Epoch 105/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 52.6722 - mae: 4.1276 - mse: 52.6722 - val_loss: 53.2611 - val_mae: 4.5433 - val_mse: 53.2611\n",
      "Epoch 106/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 52.7792 - mae: 4.2293 - mse: 52.7792 - val_loss: 66.6771 - val_mae: 4.7209 - val_mse: 66.6771\n",
      "Epoch 107/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 50.6235 - mae: 4.0280 - mse: 50.6235 - val_loss: 42.9061 - val_mae: 3.6964 - val_mse: 42.9061\n",
      "Epoch 108/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 49.7394 - mae: 4.0408 - mse: 49.7394 - val_loss: 37.3404 - val_mae: 3.6757 - val_mse: 37.3404\n",
      "Epoch 109/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 50.8936 - mae: 4.0264 - mse: 50.8936 - val_loss: 53.6764 - val_mae: 4.2364 - val_mse: 53.6764\n",
      "Epoch 110/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 50.3676 - mae: 3.9975 - mse: 50.3676 - val_loss: 49.2278 - val_mae: 4.0685 - val_mse: 49.2278\n",
      "Epoch 111/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 49.7607 - mae: 4.0485 - mse: 49.7607 - val_loss: 49.9735 - val_mae: 4.3664 - val_mse: 49.9735\n",
      "Epoch 112/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 50.2334 - mae: 4.0208 - mse: 50.2334 - val_loss: 39.6082 - val_mae: 3.7766 - val_mse: 39.6082\n",
      "Epoch 113/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 48.5554 - mae: 4.0162 - mse: 48.5554 - val_loss: 41.9847 - val_mae: 3.9819 - val_mse: 41.9847\n",
      "Epoch 114/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 49.3651 - mae: 3.9662 - mse: 49.3651 - val_loss: 38.8379 - val_mae: 3.6614 - val_mse: 38.8379\n",
      "Epoch 115/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 51.1029 - mae: 4.0844 - mse: 51.1029 - val_loss: 38.2922 - val_mae: 3.7221 - val_mse: 38.2922\n",
      "Epoch 116/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 49.6287 - mae: 4.0602 - mse: 49.6287 - val_loss: 43.9377 - val_mae: 4.4041 - val_mse: 43.9377\n",
      "Epoch 117/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 49.8712 - mae: 4.0220 - mse: 49.8712 - val_loss: 38.3317 - val_mae: 3.7013 - val_mse: 38.3317\n",
      "Epoch 118/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 49.2083 - mae: 3.9981 - mse: 49.2083 - val_loss: 39.5269 - val_mae: 3.8636 - val_mse: 39.5269\n",
      "Epoch 119/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 48.1840 - mae: 3.9695 - mse: 48.1840 - val_loss: 37.0017 - val_mae: 3.8156 - val_mse: 37.0017\n",
      "Epoch 120/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 49.0460 - mae: 4.0494 - mse: 49.0460 - val_loss: 44.1970 - val_mae: 3.9816 - val_mse: 44.1970\n",
      "Epoch 121/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 50.2578 - mae: 4.1633 - mse: 50.2578 - val_loss: 43.6590 - val_mae: 3.9268 - val_mse: 43.6590\n",
      "Epoch 122/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 49.8211 - mae: 4.0523 - mse: 49.8211 - val_loss: 37.6246 - val_mae: 3.5857 - val_mse: 37.6246\n",
      "Epoch 123/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 49.2947 - mae: 4.0116 - mse: 49.2947 - val_loss: 39.0845 - val_mae: 3.7712 - val_mse: 39.0845\n",
      "Epoch 124/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 49.0294 - mae: 4.0259 - mse: 49.0294 - val_loss: 35.2513 - val_mae: 3.6431 - val_mse: 35.2513\n",
      "Epoch 125/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 50.5097 - mae: 4.1765 - mse: 50.5097 - val_loss: 41.3865 - val_mae: 4.1114 - val_mse: 41.3865\n",
      "Epoch 126/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 47.3646 - mae: 4.0484 - mse: 47.3646 - val_loss: 42.2151 - val_mae: 3.6921 - val_mse: 42.2151\n",
      "Epoch 127/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 48.0973 - mae: 4.0652 - mse: 48.0973 - val_loss: 51.2627 - val_mae: 5.3966 - val_mse: 51.2627\n",
      "Epoch 128/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 49.1024 - mae: 4.0174 - mse: 49.1024 - val_loss: 38.3051 - val_mae: 4.1679 - val_mse: 38.3051\n",
      "Epoch 129/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 48.3531 - mae: 4.0113 - mse: 48.3531 - val_loss: 41.1043 - val_mae: 4.6225 - val_mse: 41.1043\n",
      "Epoch 130/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 47.1524 - mae: 3.9914 - mse: 47.1524 - val_loss: 36.5867 - val_mae: 4.0475 - val_mse: 36.5867\n",
      "Epoch 131/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 48.6501 - mae: 3.9933 - mse: 48.6501 - val_loss: 34.6545 - val_mae: 3.6261 - val_mse: 34.6545\n",
      "Epoch 132/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 47.1077 - mae: 3.9387 - mse: 47.1077 - val_loss: 58.9008 - val_mae: 4.5621 - val_mse: 58.9008\n",
      "Epoch 133/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 50.7876 - mae: 3.9364 - mse: 50.7876 - val_loss: 35.9321 - val_mae: 3.5818 - val_mse: 35.9321\n",
      "Epoch 134/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 47.4134 - mae: 3.9701 - mse: 47.4134 - val_loss: 41.4998 - val_mae: 3.8442 - val_mse: 41.4998\n",
      "Epoch 135/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 46.5351 - mae: 3.8711 - mse: 46.5351 - val_loss: 39.1765 - val_mae: 3.7629 - val_mse: 39.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 48.3942 - mae: 4.0306 - mse: 48.3942 - val_loss: 61.4223 - val_mae: 6.1466 - val_mse: 61.4223\n",
      "Epoch 137/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.6923 - mae: 3.8677 - mse: 46.6923 - val_loss: 39.9444 - val_mae: 3.7383 - val_mse: 39.9444\n",
      "Epoch 138/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 47.3766 - mae: 4.0031 - mse: 47.3766 - val_loss: 35.3880 - val_mae: 3.7922 - val_mse: 35.3880\n",
      "Epoch 139/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 47.1871 - mae: 3.9495 - mse: 47.1871 - val_loss: 38.2285 - val_mae: 3.7565 - val_mse: 38.2285\n",
      "Epoch 140/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.6314 - mae: 3.9316 - mse: 46.6314 - val_loss: 33.9842 - val_mae: 3.4766 - val_mse: 33.9842\n",
      "Epoch 141/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 47.2650 - mae: 3.9686 - mse: 47.2650 - val_loss: 33.4467 - val_mae: 3.5189 - val_mse: 33.4467\n",
      "Epoch 142/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 47.1994 - mae: 3.8847 - mse: 47.1994 - val_loss: 41.3940 - val_mae: 4.3882 - val_mse: 41.3940\n",
      "Epoch 143/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.8896 - mae: 3.8785 - mse: 46.8896 - val_loss: 58.8773 - val_mae: 4.4589 - val_mse: 58.8773\n",
      "Epoch 144/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 45.5034 - mae: 3.8926 - mse: 45.5034 - val_loss: 46.5215 - val_mae: 3.8475 - val_mse: 46.5215\n",
      "Epoch 145/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 47.5134 - mae: 3.9487 - mse: 47.5134 - val_loss: 49.0477 - val_mae: 4.1032 - val_mse: 49.0477\n",
      "Epoch 146/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 44.9783 - mae: 3.9188 - mse: 44.9783 - val_loss: 35.3638 - val_mae: 3.7888 - val_mse: 35.3638\n",
      "Epoch 147/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.3314 - mae: 3.8735 - mse: 46.3314 - val_loss: 45.4098 - val_mae: 3.9234 - val_mse: 45.4098\n",
      "Epoch 148/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.9433 - mae: 3.8828 - mse: 46.9433 - val_loss: 42.6094 - val_mae: 4.0877 - val_mse: 42.6094\n",
      "Epoch 149/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.8036 - mae: 3.8793 - mse: 46.8036 - val_loss: 36.5478 - val_mae: 3.8239 - val_mse: 36.5478\n",
      "Epoch 150/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 45.5654 - mae: 3.8478 - mse: 45.5654 - val_loss: 33.9851 - val_mae: 3.5459 - val_mse: 33.9851\n",
      "Epoch 151/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 45.9798 - mae: 3.9267 - mse: 45.9798 - val_loss: 61.5491 - val_mae: 5.6866 - val_mse: 61.5491\n",
      "Epoch 152/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.9074 - mae: 3.9055 - mse: 46.9074 - val_loss: 49.7196 - val_mae: 4.4959 - val_mse: 49.7196\n",
      "Epoch 153/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 46.9153 - mae: 3.8862 - mse: 46.9153 - val_loss: 37.3549 - val_mae: 3.5436 - val_mse: 37.3549\n",
      "Epoch 154/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 47.1019 - mae: 4.0099 - mse: 47.1019 - val_loss: 33.9391 - val_mae: 3.5084 - val_mse: 33.9391\n",
      "Epoch 155/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 44.4687 - mae: 3.8926 - mse: 44.4687 - val_loss: 49.3990 - val_mae: 4.1092 - val_mse: 49.3990\n",
      "Epoch 156/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 46.3284 - mae: 3.9528 - mse: 46.3284 - val_loss: 34.0008 - val_mae: 3.5210 - val_mse: 34.0008\n",
      "Epoch 157/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 45.1672 - mae: 3.8860 - mse: 45.1672 - val_loss: 42.8726 - val_mae: 3.5962 - val_mse: 42.8726\n",
      "Epoch 158/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 45.6179 - mae: 3.8372 - mse: 45.6179 - val_loss: 121.8631 - val_mae: 8.7194 - val_mse: 121.8631\n",
      "Epoch 159/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 45.4402 - mae: 3.8724 - mse: 45.4402 - val_loss: 48.4765 - val_mae: 4.1482 - val_mse: 48.4765\n",
      "Epoch 160/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 45.8250 - mae: 3.8709 - mse: 45.8250 - val_loss: 32.8948 - val_mae: 3.3540 - val_mse: 32.8948\n",
      "Epoch 161/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 45.9750 - mae: 3.8251 - mse: 45.9750 - val_loss: 58.0120 - val_mae: 5.7636 - val_mse: 58.0120\n",
      "Epoch 162/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 44.4841 - mae: 3.8554 - mse: 44.4841 - val_loss: 35.1228 - val_mae: 3.4902 - val_mse: 35.1228\n",
      "Epoch 163/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 45.2051 - mae: 3.8844 - mse: 45.2051 - val_loss: 39.5642 - val_mae: 4.4403 - val_mse: 39.5642\n",
      "Epoch 164/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 45.3661 - mae: 3.8331 - mse: 45.3661 - val_loss: 33.7439 - val_mae: 3.5801 - val_mse: 33.7439\n",
      "Epoch 165/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 45.3609 - mae: 3.8170 - mse: 45.3609 - val_loss: 34.8839 - val_mae: 3.5843 - val_mse: 34.8839\n",
      "Epoch 166/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 47.3415 - mae: 3.9037 - mse: 47.3415 - val_loss: 37.6458 - val_mae: 4.0419 - val_mse: 37.6458\n",
      "Epoch 167/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 44.2435 - mae: 3.7706 - mse: 44.2435 - val_loss: 37.7613 - val_mae: 3.7336 - val_mse: 37.7613\n",
      "Epoch 168/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 44.1584 - mae: 3.7980 - mse: 44.1584 - val_loss: 34.0818 - val_mae: 3.6679 - val_mse: 34.0818\n",
      "Epoch 169/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 45.2151 - mae: 3.8337 - mse: 45.2151 - val_loss: 34.7868 - val_mae: 3.6998 - val_mse: 34.7868\n",
      "Epoch 170/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 43.5998 - mae: 3.7579 - mse: 43.5998 - val_loss: 47.3169 - val_mae: 4.7694 - val_mse: 47.3168\n",
      "Epoch 171/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 46.1972 - mae: 3.8844 - mse: 46.1972 - val_loss: 34.6103 - val_mae: 3.4557 - val_mse: 34.6103\n",
      "Epoch 172/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 43.9408 - mae: 3.7693 - mse: 43.9408 - val_loss: 38.7611 - val_mae: 3.7275 - val_mse: 38.7611\n",
      "Epoch 173/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 44.8577 - mae: 3.8471 - mse: 44.8577 - val_loss: 101.5190 - val_mae: 8.3761 - val_mse: 101.5190\n",
      "Epoch 174/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 44.0279 - mae: 3.8342 - mse: 44.0279 - val_loss: 32.1210 - val_mae: 3.2918 - val_mse: 32.1210\n",
      "Epoch 175/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 45.6646 - mae: 3.9488 - mse: 45.6646 - val_loss: 31.0136 - val_mae: 3.4527 - val_mse: 31.0136\n",
      "Epoch 176/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 44.8722 - mae: 3.8721 - mse: 44.8722 - val_loss: 47.9957 - val_mae: 5.5137 - val_mse: 47.9957\n",
      "Epoch 177/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 44.3190 - mae: 3.8391 - mse: 44.3190 - val_loss: 30.6879 - val_mae: 3.4185 - val_mse: 30.6879\n",
      "Epoch 178/1000\n",
      "3852/3852 [==============================] - 0s 44us/step - loss: 45.2705 - mae: 3.8753 - mse: 45.2705 - val_loss: 35.1235 - val_mae: 3.4571 - val_mse: 35.1235\n",
      "Epoch 179/1000\n",
      "3852/3852 [==============================] - 0s 72us/step - loss: 44.3793 - mae: 3.8370 - mse: 44.3793 - val_loss: 34.4512 - val_mae: 3.7327 - val_mse: 34.4512\n",
      "Epoch 180/1000\n",
      "3852/3852 [==============================] - 0s 66us/step - loss: 44.7408 - mae: 3.8484 - mse: 44.7408 - val_loss: 30.4294 - val_mae: 3.2418 - val_mse: 30.4294\n",
      "Epoch 181/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 42.2468 - mae: 3.6948 - mse: 42.2468 - val_loss: 47.5545 - val_mae: 4.4055 - val_mse: 47.5545\n",
      "Epoch 182/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 43.6878 - mae: 3.7768 - mse: 43.6878 - val_loss: 34.4958 - val_mae: 3.5491 - val_mse: 34.4958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 43.9008 - mae: 3.7269 - mse: 43.9008 - val_loss: 95.2209 - val_mae: 7.9881 - val_mse: 95.2209\n",
      "Epoch 184/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 45.3661 - mae: 3.8308 - mse: 45.3662 - val_loss: 35.5409 - val_mae: 3.5538 - val_mse: 35.5409\n",
      "Epoch 185/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 43.2708 - mae: 3.7588 - mse: 43.2708 - val_loss: 47.4075 - val_mae: 4.3623 - val_mse: 47.4076\n",
      "Epoch 186/1000\n",
      "3852/3852 [==============================] - 0s 51us/step - loss: 44.3119 - mae: 3.8528 - mse: 44.3119 - val_loss: 32.7409 - val_mae: 3.3889 - val_mse: 32.7409\n",
      "Epoch 187/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 43.6644 - mae: 3.6781 - mse: 43.6644 - val_loss: 36.0940 - val_mae: 4.0730 - val_mse: 36.0940\n",
      "Epoch 188/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 47.1573 - mae: 3.9574 - mse: 47.1573 - val_loss: 31.6427 - val_mae: 3.2650 - val_mse: 31.6427\n",
      "Epoch 189/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 45.4423 - mae: 3.9252 - mse: 45.4423 - val_loss: 46.9545 - val_mae: 4.1811 - val_mse: 46.9545\n",
      "Epoch 190/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 45.0274 - mae: 3.8481 - mse: 45.0274 - val_loss: 64.2272 - val_mae: 4.8342 - val_mse: 64.2272\n",
      "Epoch 191/1000\n",
      "3852/3852 [==============================] - 0s 41us/step - loss: 43.3976 - mae: 3.7673 - mse: 43.3976 - val_loss: 57.1544 - val_mae: 5.2400 - val_mse: 57.1544\n",
      "Epoch 192/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 43.3942 - mae: 3.7603 - mse: 43.3942 - val_loss: 66.8208 - val_mae: 5.8652 - val_mse: 66.8208\n",
      "Epoch 193/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 42.8030 - mae: 3.7752 - mse: 42.8030 - val_loss: 33.7154 - val_mae: 3.6750 - val_mse: 33.7154\n",
      "Epoch 194/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 44.1600 - mae: 3.8376 - mse: 44.1600 - val_loss: 30.0496 - val_mae: 3.4010 - val_mse: 30.0496\n",
      "Epoch 195/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 42.8566 - mae: 3.7949 - mse: 42.8566 - val_loss: 57.2015 - val_mae: 4.7529 - val_mse: 57.2014\n",
      "Epoch 196/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 42.0576 - mae: 3.6750 - mse: 42.0576 - val_loss: 38.7126 - val_mae: 3.6590 - val_mse: 38.7126\n",
      "Epoch 197/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 44.1569 - mae: 3.7610 - mse: 44.1569 - val_loss: 33.2884 - val_mae: 3.4058 - val_mse: 33.2884\n",
      "Epoch 198/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 43.3221 - mae: 3.7171 - mse: 43.3221 - val_loss: 30.3058 - val_mae: 3.1950 - val_mse: 30.3058\n",
      "Epoch 199/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 44.4465 - mae: 3.7138 - mse: 44.4465 - val_loss: 38.8527 - val_mae: 4.1036 - val_mse: 38.8527\n",
      "Epoch 200/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 43.8735 - mae: 3.6973 - mse: 43.8735 - val_loss: 32.0062 - val_mae: 3.3589 - val_mse: 32.0062\n",
      "Epoch 201/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 43.7226 - mae: 3.6884 - mse: 43.7226 - val_loss: 42.3064 - val_mae: 3.8246 - val_mse: 42.3064\n",
      "Epoch 202/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 44.3648 - mae: 3.7094 - mse: 44.3648 - val_loss: 31.1056 - val_mae: 3.2635 - val_mse: 31.1056\n",
      "Epoch 203/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 45.2706 - mae: 3.8162 - mse: 45.2706 - val_loss: 31.6754 - val_mae: 3.4377 - val_mse: 31.6754\n",
      "Epoch 204/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 44.2573 - mae: 3.7668 - mse: 44.2573 - val_loss: 58.4671 - val_mae: 5.4040 - val_mse: 58.4671\n",
      "Epoch 205/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 42.5580 - mae: 3.7478 - mse: 42.5579 - val_loss: 33.0140 - val_mae: 3.3461 - val_mse: 33.0140\n",
      "Epoch 206/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 42.7423 - mae: 3.8350 - mse: 42.7423 - val_loss: 34.6589 - val_mae: 3.5041 - val_mse: 34.6589\n",
      "Epoch 207/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 42.5767 - mae: 3.7575 - mse: 42.5767 - val_loss: 30.6874 - val_mae: 3.2568 - val_mse: 30.6874\n",
      "Epoch 208/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 42.1877 - mae: 3.7551 - mse: 42.1877 - val_loss: 32.9164 - val_mae: 3.7047 - val_mse: 32.9164\n",
      "Epoch 209/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 43.2589 - mae: 3.7719 - mse: 43.2589 - val_loss: 178.1275 - val_mae: 11.5338 - val_mse: 178.1276\n",
      "Epoch 210/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 44.2386 - mae: 3.8178 - mse: 44.2385 - val_loss: 46.1371 - val_mae: 4.9635 - val_mse: 46.1371\n",
      "Epoch 211/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 43.3652 - mae: 3.7683 - mse: 43.3652 - val_loss: 33.1669 - val_mae: 3.6340 - val_mse: 33.1669\n",
      "Epoch 212/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 44.1099 - mae: 3.7500 - mse: 44.1099 - val_loss: 85.3561 - val_mae: 7.6283 - val_mse: 85.3561\n",
      "Epoch 213/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 43.2556 - mae: 3.7180 - mse: 43.2556 - val_loss: 45.5099 - val_mae: 3.8880 - val_mse: 45.5099\n",
      "Epoch 214/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 43.8914 - mae: 3.7100 - mse: 43.8914 - val_loss: 32.3025 - val_mae: 3.3003 - val_mse: 32.3025\n",
      "Epoch 215/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 43.0831 - mae: 3.7115 - mse: 43.0831 - val_loss: 37.0544 - val_mae: 3.5907 - val_mse: 37.0544\n",
      "Epoch 216/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 41.9213 - mae: 3.7135 - mse: 41.9213 - val_loss: 57.7033 - val_mae: 4.3770 - val_mse: 57.7033\n",
      "Epoch 217/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 43.4095 - mae: 3.7384 - mse: 43.4095 - val_loss: 32.1700 - val_mae: 3.3814 - val_mse: 32.1700\n",
      "Epoch 218/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 42.3416 - mae: 3.7138 - mse: 42.3416 - val_loss: 44.4314 - val_mae: 4.8795 - val_mse: 44.4314\n",
      "Epoch 219/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 43.3400 - mae: 3.7712 - mse: 43.3400 - val_loss: 34.5423 - val_mae: 3.5672 - val_mse: 34.5423\n",
      "Epoch 220/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 43.4083 - mae: 3.7066 - mse: 43.4083 - val_loss: 37.3073 - val_mae: 3.6530 - val_mse: 37.3073\n",
      "Epoch 221/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 42.5454 - mae: 3.7010 - mse: 42.5454 - val_loss: 33.2180 - val_mae: 3.5382 - val_mse: 33.2180\n",
      "Epoch 222/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 52.3835 - mae: 3.7121 - mse: 52.3834 - val_loss: 39.2798 - val_mae: 3.7512 - val_mse: 39.2798\n",
      "Epoch 223/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 42.0007 - mae: 3.6594 - mse: 42.0007 - val_loss: 33.3580 - val_mae: 3.9392 - val_mse: 33.3580\n",
      "Epoch 224/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 42.4120 - mae: 3.7165 - mse: 42.4120 - val_loss: 33.2863 - val_mae: 3.4426 - val_mse: 33.2863\n",
      "Epoch 225/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 42.8276 - mae: 3.7353 - mse: 42.8275 - val_loss: 31.2181 - val_mae: 3.5097 - val_mse: 31.2181\n",
      "Epoch 226/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 42.4620 - mae: 3.7063 - mse: 42.4620 - val_loss: 32.8524 - val_mae: 3.6271 - val_mse: 32.8524\n",
      "Epoch 227/1000\n",
      "3852/3852 [==============================] - 0s 45us/step - loss: 42.8401 - mae: 3.7704 - mse: 42.8401 - val_loss: 90.9359 - val_mae: 7.9363 - val_mse: 90.9359\n",
      "Epoch 228/1000\n",
      "3852/3852 [==============================] - 0s 42us/step - loss: 40.8082 - mae: 3.6742 - mse: 40.8082 - val_loss: 61.7287 - val_mae: 5.6249 - val_mse: 61.7287\n",
      "Epoch 229/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 40.5465 - mae: 3.6068 - mse: 40.5465 - val_loss: 31.1053 - val_mae: 3.3632 - val_mse: 31.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 41.9988 - mae: 3.6996 - mse: 41.9988 - val_loss: 40.7000 - val_mae: 4.1993 - val_mse: 40.7000\n",
      "Epoch 231/1000\n",
      "3852/3852 [==============================] - 0s 52us/step - loss: 42.2055 - mae: 3.6683 - mse: 42.2054 - val_loss: 66.9978 - val_mae: 6.3916 - val_mse: 66.9978\n",
      "Epoch 232/1000\n",
      "3852/3852 [==============================] - 0s 54us/step - loss: 41.3358 - mae: 3.6228 - mse: 41.3358 - val_loss: 29.8310 - val_mae: 3.2696 - val_mse: 29.8310\n",
      "Epoch 233/1000\n",
      "3852/3852 [==============================] - 0s 60us/step - loss: 43.1368 - mae: 3.8391 - mse: 43.1368 - val_loss: 53.4666 - val_mae: 5.2452 - val_mse: 53.4666\n",
      "Epoch 234/1000\n",
      "3852/3852 [==============================] - 0s 52us/step - loss: 41.6750 - mae: 3.6682 - mse: 41.6750 - val_loss: 35.3498 - val_mae: 3.5116 - val_mse: 35.3498\n",
      "Epoch 235/1000\n",
      "3852/3852 [==============================] - 0s 42us/step - loss: 41.3339 - mae: 3.7776 - mse: 41.3339 - val_loss: 29.1353 - val_mae: 3.1801 - val_mse: 29.1353\n",
      "Epoch 236/1000\n",
      "3852/3852 [==============================] - 0s 57us/step - loss: 40.7277 - mae: 3.7406 - mse: 40.7277 - val_loss: 32.5648 - val_mae: 3.6052 - val_mse: 32.5648\n",
      "Epoch 237/1000\n",
      "3852/3852 [==============================] - 0s 46us/step - loss: 41.3739 - mae: 3.6536 - mse: 41.3739 - val_loss: 32.5380 - val_mae: 3.3301 - val_mse: 32.5380\n",
      "Epoch 238/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 43.4498 - mae: 3.7784 - mse: 43.4498 - val_loss: 53.3935 - val_mae: 5.1717 - val_mse: 53.3935\n",
      "Epoch 239/1000\n",
      "3852/3852 [==============================] - 0s 42us/step - loss: 41.4528 - mae: 3.7736 - mse: 41.4528 - val_loss: 35.5013 - val_mae: 3.6558 - val_mse: 35.5013\n",
      "Epoch 240/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 41.6902 - mae: 3.7012 - mse: 41.6902 - val_loss: 31.4806 - val_mae: 3.4454 - val_mse: 31.4806\n",
      "Epoch 241/1000\n",
      "3852/3852 [==============================] - 0s 51us/step - loss: 41.8719 - mae: 3.6308 - mse: 41.8719 - val_loss: 33.0841 - val_mae: 3.5016 - val_mse: 33.0841\n",
      "Epoch 242/1000\n",
      "3852/3852 [==============================] - 0s 70us/step - loss: 41.0437 - mae: 3.6752 - mse: 41.0437 - val_loss: 28.8819 - val_mae: 3.2871 - val_mse: 28.8819\n",
      "Epoch 243/1000\n",
      "3852/3852 [==============================] - 0s 44us/step - loss: 41.1490 - mae: 3.6463 - mse: 41.1490 - val_loss: 36.3661 - val_mae: 3.6049 - val_mse: 36.3661\n",
      "Epoch 244/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 40.8135 - mae: 3.6634 - mse: 40.8135 - val_loss: 33.6192 - val_mae: 3.6183 - val_mse: 33.6192\n",
      "Epoch 245/1000\n",
      "3852/3852 [==============================] - 0s 59us/step - loss: 40.0271 - mae: 3.6056 - mse: 40.0271 - val_loss: 46.8968 - val_mae: 4.4855 - val_mse: 46.8968\n",
      "Epoch 246/1000\n",
      "3852/3852 [==============================] - 3s 795us/step - loss: 40.2603 - mae: 3.5923 - mse: 40.2603 - val_loss: 202.2631 - val_mae: 12.2605 - val_mse: 202.2631097 - mae: 3.6443  - ETA: 0s - loss: 39.9263 - mae: 3.5764 - mse: 39.926\n",
      "Epoch 247/1000\n",
      "3852/3852 [==============================] - 0s 102us/step - loss: 43.1520 - mae: 3.7171 - mse: 43.1520 - val_loss: 67.0516 - val_mae: 5.9726 - val_mse: 67.0516\n",
      "Epoch 248/1000\n",
      "3852/3852 [==============================] - 0s 88us/step - loss: 40.9096 - mae: 3.5876 - mse: 40.9096 - val_loss: 72.2488 - val_mae: 6.0182 - val_mse: 72.2488\n",
      "Epoch 249/1000\n",
      "3852/3852 [==============================] - 0s 94us/step - loss: 41.1599 - mae: 3.6576 - mse: 41.1599 - val_loss: 33.5293 - val_mae: 3.3824 - val_mse: 33.5293\n",
      "Epoch 250/1000\n",
      "3852/3852 [==============================] - 0s 81us/step - loss: 41.2046 - mae: 3.6645 - mse: 41.2046 - val_loss: 30.7085 - val_mae: 3.3022 - val_mse: 30.7085\n",
      "Epoch 251/1000\n",
      "3852/3852 [==============================] - 0s 75us/step - loss: 42.2471 - mae: 3.7090 - mse: 42.2470 - val_loss: 53.6791 - val_mae: 4.9955 - val_mse: 53.6790\n",
      "Epoch 252/1000\n",
      "3852/3852 [==============================] - 0s 81us/step - loss: 39.9237 - mae: 3.6439 - mse: 39.9237 - val_loss: 37.7479 - val_mae: 4.2662 - val_mse: 37.7479\n",
      "Epoch 253/1000\n",
      "3852/3852 [==============================] - 0s 77us/step - loss: 41.7445 - mae: 3.6813 - mse: 41.7446 - val_loss: 41.8321 - val_mae: 3.9407 - val_mse: 41.8321\n",
      "Epoch 254/1000\n",
      "3852/3852 [==============================] - 0s 76us/step - loss: 41.0109 - mae: 3.6213 - mse: 41.0109 - val_loss: 42.3986 - val_mae: 4.2627 - val_mse: 42.3986\n",
      "Epoch 255/1000\n",
      "3852/3852 [==============================] - 0s 75us/step - loss: 40.8892 - mae: 3.6338 - mse: 40.8892 - val_loss: 34.4293 - val_mae: 3.4258 - val_mse: 34.4293\n",
      "Epoch 256/1000\n",
      "3852/3852 [==============================] - 0s 81us/step - loss: 39.6889 - mae: 3.5918 - mse: 39.6889 - val_loss: 30.9811 - val_mae: 3.2971 - val_mse: 30.9811\n",
      "Epoch 257/1000\n",
      "3852/3852 [==============================] - 0s 96us/step - loss: 40.9837 - mae: 3.7056 - mse: 40.9837 - val_loss: 45.1112 - val_mae: 4.4198 - val_mse: 45.1112\n",
      "Epoch 258/1000\n",
      "3852/3852 [==============================] - 0s 84us/step - loss: 40.3658 - mae: 3.6480 - mse: 40.3658 - val_loss: 109.2938 - val_mae: 8.1174 - val_mse: 109.2938\n",
      "Epoch 259/1000\n",
      "3852/3852 [==============================] - 0s 93us/step - loss: 41.5371 - mae: 3.6736 - mse: 41.5371 - val_loss: 34.4650 - val_mae: 3.8377 - val_mse: 34.4650\n",
      "Epoch 260/1000\n",
      "3852/3852 [==============================] - 0s 78us/step - loss: 40.0403 - mae: 3.6412 - mse: 40.0403 - val_loss: 31.9186 - val_mae: 3.5264 - val_mse: 31.9186\n",
      "Epoch 261/1000\n",
      "3852/3852 [==============================] - 0s 90us/step - loss: 41.2370 - mae: 3.6343 - mse: 41.2370 - val_loss: 31.6137 - val_mae: 3.4207 - val_mse: 31.6137\n",
      "Epoch 262/1000\n",
      "3852/3852 [==============================] - 0s 97us/step - loss: 41.4442 - mae: 3.6786 - mse: 41.4442 - val_loss: 30.1885 - val_mae: 3.2345 - val_mse: 30.1885\n",
      "Epoch 263/1000\n",
      "3852/3852 [==============================] - 0s 92us/step - loss: 38.7773 - mae: 3.5896 - mse: 38.7773 - val_loss: 37.4842 - val_mae: 3.8607 - val_mse: 37.4842\n",
      "Epoch 264/1000\n",
      "3852/3852 [==============================] - 0s 90us/step - loss: 41.0361 - mae: 3.6293 - mse: 41.0361 - val_loss: 28.7105 - val_mae: 3.2272 - val_mse: 28.7106\n",
      "Epoch 265/1000\n",
      "3852/3852 [==============================] - 0s 77us/step - loss: 40.5791 - mae: 3.6636 - mse: 40.5791 - val_loss: 41.7731 - val_mae: 4.5416 - val_mse: 41.7731\n",
      "Epoch 266/1000\n",
      "3852/3852 [==============================] - 0s 75us/step - loss: 41.9009 - mae: 3.6547 - mse: 41.9009 - val_loss: 34.2493 - val_mae: 3.8746 - val_mse: 34.2493\n",
      "Epoch 267/1000\n",
      "3852/3852 [==============================] - 0s 73us/step - loss: 40.8986 - mae: 3.5888 - mse: 40.8986 - val_loss: 55.3043 - val_mae: 4.8728 - val_mse: 55.3043\n",
      "Epoch 268/1000\n",
      "3852/3852 [==============================] - 0s 83us/step - loss: 40.8019 - mae: 3.6597 - mse: 40.8019 - val_loss: 27.9341 - val_mae: 3.1321 - val_mse: 27.9341\n",
      "Epoch 269/1000\n",
      "3852/3852 [==============================] - 0s 90us/step - loss: 39.0031 - mae: 3.5902 - mse: 39.0031 - val_loss: 37.5505 - val_mae: 3.6791 - val_mse: 37.5505\n",
      "Epoch 270/1000\n",
      "3852/3852 [==============================] - 0s 78us/step - loss: 39.4134 - mae: 3.6459 - mse: 39.4134 - val_loss: 30.6908 - val_mae: 3.3812 - val_mse: 30.6908\n",
      "Epoch 271/1000\n",
      "3852/3852 [==============================] - 0s 81us/step - loss: 39.4087 - mae: 3.5578 - mse: 39.4087 - val_loss: 28.7049 - val_mae: 3.2486 - val_mse: 28.7049\n",
      "Epoch 272/1000\n",
      "3852/3852 [==============================] - 0s 81us/step - loss: 39.4192 - mae: 3.5757 - mse: 39.4192 - val_loss: 30.6054 - val_mae: 3.1811 - val_mse: 30.6054\n",
      "Epoch 273/1000\n",
      "3852/3852 [==============================] - 0s 74us/step - loss: 40.7272 - mae: 3.6402 - mse: 40.7272 - val_loss: 29.1005 - val_mae: 3.3418 - val_mse: 29.1005\n",
      "Epoch 274/1000\n",
      "3852/3852 [==============================] - 0s 74us/step - loss: 41.4840 - mae: 3.6535 - mse: 41.4840 - val_loss: 32.9866 - val_mae: 3.7910 - val_mse: 32.9866\n",
      "Epoch 275/1000\n",
      "3852/3852 [==============================] - 0s 71us/step - loss: 37.8355 - mae: 3.5288 - mse: 37.8354 - val_loss: 31.6314 - val_mae: 3.3760 - val_mse: 31.6314\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852/3852 [==============================] - 0s 69us/step - loss: 39.8786 - mae: 3.6475 - mse: 39.8786 - val_loss: 33.0026 - val_mae: 3.6801 - val_mse: 33.0026\n",
      "Epoch 277/1000\n",
      "3852/3852 [==============================] - 0s 70us/step - loss: 39.4824 - mae: 3.6286 - mse: 39.4824 - val_loss: 33.4281 - val_mae: 3.4030 - val_mse: 33.4281\n",
      "Epoch 278/1000\n",
      "3852/3852 [==============================] - 0s 73us/step - loss: 40.6966 - mae: 3.5642 - mse: 40.6966 - val_loss: 43.5608 - val_mae: 4.0858 - val_mse: 43.5608\n",
      "Epoch 279/1000\n",
      "3852/3852 [==============================] - 0s 73us/step - loss: 40.9113 - mae: 3.5804 - mse: 40.9113 - val_loss: 33.9117 - val_mae: 3.8443 - val_mse: 33.9117\n",
      "Epoch 280/1000\n",
      "3852/3852 [==============================] - 0s 69us/step - loss: 41.9463 - mae: 3.6298 - mse: 41.9463 - val_loss: 42.8898 - val_mae: 4.0348 - val_mse: 42.8898\n",
      "Epoch 281/1000\n",
      "3852/3852 [==============================] - 0s 70us/step - loss: 40.6924 - mae: 3.5044 - mse: 40.6924 - val_loss: 38.5943 - val_mae: 4.0215 - val_mse: 38.5943\n",
      "Epoch 282/1000\n",
      "3852/3852 [==============================] - 0s 67us/step - loss: 40.0126 - mae: 3.6131 - mse: 40.0126 - val_loss: 32.0948 - val_mae: 3.3833 - val_mse: 32.0948\n",
      "Epoch 283/1000\n",
      "3852/3852 [==============================] - 0s 81us/step - loss: 39.7591 - mae: 3.5184 - mse: 39.7591 - val_loss: 33.6058 - val_mae: 3.5598 - val_mse: 33.6058\n",
      "Epoch 284/1000\n",
      "3852/3852 [==============================] - 0s 71us/step - loss: 39.9345 - mae: 3.5686 - mse: 39.9345 - val_loss: 31.3943 - val_mae: 3.2844 - val_mse: 31.3943\n",
      "Epoch 285/1000\n",
      "3852/3852 [==============================] - 0s 68us/step - loss: 39.1984 - mae: 3.5695 - mse: 39.1984 - val_loss: 46.7835 - val_mae: 4.1439 - val_mse: 46.7835\n",
      "Epoch 286/1000\n",
      "3852/3852 [==============================] - 0s 72us/step - loss: 41.3672 - mae: 3.7113 - mse: 41.3672 - val_loss: 30.5256 - val_mae: 3.4693 - val_mse: 30.5256\n",
      "Epoch 287/1000\n",
      "3852/3852 [==============================] - 0s 71us/step - loss: 41.1082 - mae: 3.6398 - mse: 41.1082 - val_loss: 31.9686 - val_mae: 3.3535 - val_mse: 31.9686\n",
      "Epoch 288/1000\n",
      "3852/3852 [==============================] - 0s 70us/step - loss: 40.3244 - mae: 3.6044 - mse: 40.3244 - val_loss: 41.1140 - val_mae: 4.0119 - val_mse: 41.1140\n",
      "Epoch 289/1000\n",
      "3852/3852 [==============================] - 0s 69us/step - loss: 40.4852 - mae: 3.5824 - mse: 40.4853 - val_loss: 46.2788 - val_mae: 5.2086 - val_mse: 46.2788\n",
      "Epoch 290/1000\n",
      "3852/3852 [==============================] - 0s 68us/step - loss: 40.6571 - mae: 3.6063 - mse: 40.6571 - val_loss: 37.9543 - val_mae: 4.1147 - val_mse: 37.9543\n",
      "Epoch 291/1000\n",
      "3852/3852 [==============================] - 0s 65us/step - loss: 40.9903 - mae: 3.5320 - mse: 40.9903 - val_loss: 29.3383 - val_mae: 3.2699 - val_mse: 29.3383\n",
      "Epoch 292/1000\n",
      "3852/3852 [==============================] - 0s 67us/step - loss: 40.6720 - mae: 3.5791 - mse: 40.6720 - val_loss: 30.9187 - val_mae: 3.4262 - val_mse: 30.9187\n",
      "Epoch 293/1000\n",
      "3852/3852 [==============================] - 0s 66us/step - loss: 41.2876 - mae: 3.5886 - mse: 41.2876 - val_loss: 37.8199 - val_mae: 4.0030 - val_mse: 37.8199\n",
      "Epoch 294/1000\n",
      "3852/3852 [==============================] - 0s 66us/step - loss: 40.0944 - mae: 3.5610 - mse: 40.0944 - val_loss: 33.2944 - val_mae: 3.6252 - val_mse: 33.2944\n",
      "Epoch 295/1000\n",
      "3852/3852 [==============================] - 0s 64us/step - loss: 38.8602 - mae: 3.5206 - mse: 38.8602 - val_loss: 33.5531 - val_mae: 4.0338 - val_mse: 33.5531\n",
      "Epoch 296/1000\n",
      "3852/3852 [==============================] - 0s 65us/step - loss: 39.5381 - mae: 3.6119 - mse: 39.5381 - val_loss: 43.6006 - val_mae: 3.9607 - val_mse: 43.6006\n",
      "Epoch 297/1000\n",
      "3852/3852 [==============================] - 0s 66us/step - loss: 40.5086 - mae: 3.6344 - mse: 40.5086 - val_loss: 35.9101 - val_mae: 3.6058 - val_mse: 35.9101\n",
      "Epoch 298/1000\n",
      "3852/3852 [==============================] - 0s 67us/step - loss: 38.8676 - mae: 3.5939 - mse: 38.8676 - val_loss: 31.8650 - val_mae: 3.4471 - val_mse: 31.8650\n",
      "Epoch 299/1000\n",
      "3852/3852 [==============================] - 0s 72us/step - loss: 40.0242 - mae: 3.5889 - mse: 40.0242 - val_loss: 31.7991 - val_mae: 3.4906 - val_mse: 31.7991\n",
      "Epoch 300/1000\n",
      "3852/3852 [==============================] - 0s 75us/step - loss: 39.5919 - mae: 3.5894 - mse: 39.5919 - val_loss: 28.8240 - val_mae: 3.1988 - val_mse: 28.8240\n",
      "Epoch 301/1000\n",
      "3852/3852 [==============================] - 0s 82us/step - loss: 40.2275 - mae: 3.5993 - mse: 40.2275 - val_loss: 30.4343 - val_mae: 3.4404 - val_mse: 30.4343\n",
      "Epoch 302/1000\n",
      "3852/3852 [==============================] - 0s 64us/step - loss: 38.0757 - mae: 3.5085 - mse: 38.0757 - val_loss: 28.1368 - val_mae: 3.2643 - val_mse: 28.1368\n",
      "Epoch 303/1000\n",
      "3852/3852 [==============================] - 0s 64us/step - loss: 38.4053 - mae: 3.5181 - mse: 38.4053 - val_loss: 29.7441 - val_mae: 3.3024 - val_mse: 29.7441\n",
      "Epoch 304/1000\n",
      "3852/3852 [==============================] - 0s 72us/step - loss: 40.9421 - mae: 3.6001 - mse: 40.9421 - val_loss: 34.6998 - val_mae: 3.8762 - val_mse: 34.6998\n",
      "Epoch 305/1000\n",
      "3852/3852 [==============================] - 0s 66us/step - loss: 40.1219 - mae: 3.6467 - mse: 40.1219 - val_loss: 32.4341 - val_mae: 3.4375 - val_mse: 32.4341\n",
      "Epoch 306/1000\n",
      "3852/3852 [==============================] - 0s 77us/step - loss: 39.1638 - mae: 3.5923 - mse: 39.1638 - val_loss: 31.4645 - val_mae: 3.3371 - val_mse: 31.4645\n",
      "Epoch 307/1000\n",
      "3852/3852 [==============================] - 0s 64us/step - loss: 39.4813 - mae: 3.5512 - mse: 39.4813 - val_loss: 32.5081 - val_mae: 3.3484 - val_mse: 32.5081\n",
      "Epoch 308/1000\n",
      "3852/3852 [==============================] - 0s 66us/step - loss: 40.1127 - mae: 3.5689 - mse: 40.1127 - val_loss: 50.3675 - val_mae: 5.2104 - val_mse: 50.3675\n",
      "Epoch 309/1000\n",
      "3852/3852 [==============================] - 0s 64us/step - loss: 39.7186 - mae: 3.5751 - mse: 39.7186 - val_loss: 34.8671 - val_mae: 3.4049 - val_mse: 34.8671\n",
      "Epoch 310/1000\n",
      "3852/3852 [==============================] - 0s 71us/step - loss: 39.7971 - mae: 3.5695 - mse: 39.7971 - val_loss: 31.0778 - val_mae: 3.5861 - val_mse: 31.0778\n",
      "Epoch 311/1000\n",
      "3852/3852 [==============================] - 0s 67us/step - loss: 37.8820 - mae: 3.4979 - mse: 37.8820 - val_loss: 90.8403 - val_mae: 6.5807 - val_mse: 90.8403\n",
      "Epoch 312/1000\n",
      "3852/3852 [==============================] - 0s 70us/step - loss: 40.7130 - mae: 3.5674 - mse: 40.7130 - val_loss: 34.4381 - val_mae: 3.4962 - val_mse: 34.4381\n",
      "Epoch 313/1000\n",
      "3852/3852 [==============================] - 0s 56us/step - loss: 40.2196 - mae: 3.6003 - mse: 40.2196 - val_loss: 39.0742 - val_mae: 3.7600 - val_mse: 39.0742\n",
      "Epoch 314/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.0264 - mae: 3.5679 - mse: 39.0264 - val_loss: 31.4384 - val_mae: 3.2894 - val_mse: 31.4384\n",
      "Epoch 315/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.5206 - mae: 3.5769 - mse: 40.5206 - val_loss: 29.3238 - val_mae: 3.1976 - val_mse: 29.3238\n",
      "Epoch 316/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 38.7452 - mae: 3.5255 - mse: 38.7452 - val_loss: 35.7904 - val_mae: 3.4010 - val_mse: 35.7904\n",
      "Epoch 317/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.1127 - mae: 3.5326 - mse: 40.1127 - val_loss: 35.7779 - val_mae: 3.7228 - val_mse: 35.7779\n",
      "Epoch 318/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 39.4466 - mae: 3.5270 - mse: 39.4466 - val_loss: 31.5246 - val_mae: 3.4284 - val_mse: 31.5246\n",
      "Epoch 319/1000\n",
      "3852/3852 [==============================] - 0s 43us/step - loss: 38.7887 - mae: 3.4663 - mse: 38.7887 - val_loss: 37.9944 - val_mae: 3.6000 - val_mse: 37.9944\n",
      "Epoch 320/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1797 - mae: 3.4425 - mse: 38.1797 - val_loss: 28.6790 - val_mae: 3.0897 - val_mse: 28.6790\n",
      "Epoch 321/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.7237 - mae: 3.5056 - mse: 37.7237 - val_loss: 38.8664 - val_mae: 3.6300 - val_mse: 38.8664\n",
      "Epoch 322/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.4213 - mae: 3.4010 - mse: 37.4213 - val_loss: 30.2803 - val_mae: 3.2488 - val_mse: 30.2803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.2084 - mae: 3.5504 - mse: 40.2084 - val_loss: 35.4219 - val_mae: 3.4045 - val_mse: 35.4219\n",
      "Epoch 324/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 40.9883 - mae: 3.5907 - mse: 40.9883 - val_loss: 33.7362 - val_mae: 3.6552 - val_mse: 33.7362\n",
      "Epoch 325/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.6341 - mae: 3.6098 - mse: 40.6341 - val_loss: 29.0350 - val_mae: 3.2028 - val_mse: 29.0350\n",
      "Epoch 326/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.3497 - mae: 3.4765 - mse: 39.3497 - val_loss: 43.3601 - val_mae: 4.4155 - val_mse: 43.3601\n",
      "Epoch 327/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.6471 - mae: 3.5317 - mse: 39.6471 - val_loss: 35.1895 - val_mae: 3.5441 - val_mse: 35.1895\n",
      "Epoch 328/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 41.0117 - mae: 3.5427 - mse: 41.0118 - val_loss: 42.0473 - val_mae: 3.8398 - val_mse: 42.0473\n",
      "Epoch 329/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.9213 - mae: 3.5020 - mse: 38.9213 - val_loss: 43.6860 - val_mae: 4.3273 - val_mse: 43.6860\n",
      "Epoch 330/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8014 - mae: 3.5269 - mse: 38.8013 - val_loss: 33.1457 - val_mae: 3.5122 - val_mse: 33.1457\n",
      "Epoch 331/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.3517 - mae: 3.4826 - mse: 38.3517 - val_loss: 31.8131 - val_mae: 3.3485 - val_mse: 31.8131\n",
      "Epoch 332/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.3800 - mae: 3.5219 - mse: 38.3800 - val_loss: 29.3521 - val_mae: 3.3071 - val_mse: 29.3521\n",
      "Epoch 333/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 40.5938 - mae: 3.5784 - mse: 40.5938 - val_loss: 103.1335 - val_mae: 8.3192 - val_mse: 103.1335\n",
      "Epoch 334/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.9929 - mae: 3.5930 - mse: 40.9929 - val_loss: 29.8517 - val_mae: 3.3326 - val_mse: 29.8517\n",
      "Epoch 335/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 39.2531 - mae: 3.5022 - mse: 39.2530 - val_loss: 30.3777 - val_mae: 3.2277 - val_mse: 30.3777\n",
      "Epoch 336/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.8158 - mae: 3.3898 - mse: 37.8158 - val_loss: 32.4694 - val_mae: 3.2466 - val_mse: 32.4694\n",
      "Epoch 337/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 37.8033 - mae: 3.4462 - mse: 37.8033 - val_loss: 28.4592 - val_mae: 3.1119 - val_mse: 28.4592\n",
      "Epoch 338/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.5233 - mae: 3.4946 - mse: 40.5233 - val_loss: 34.1154 - val_mae: 3.7337 - val_mse: 34.1154\n",
      "Epoch 339/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.1341 - mae: 3.5135 - mse: 40.1341 - val_loss: 46.7496 - val_mae: 4.1677 - val_mse: 46.7496\n",
      "Epoch 340/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 39.0096 - mae: 3.5056 - mse: 39.0096 - val_loss: 33.1035 - val_mae: 3.4473 - val_mse: 33.1035\n",
      "Epoch 341/1000\n",
      "3852/3852 [==============================] - 0s 41us/step - loss: 39.0706 - mae: 3.4729 - mse: 39.0706 - val_loss: 30.2933 - val_mae: 3.4125 - val_mse: 30.2933\n",
      "Epoch 342/1000\n",
      "3852/3852 [==============================] - 0s 41us/step - loss: 40.2921 - mae: 3.5159 - mse: 40.2921 - val_loss: 62.4741 - val_mae: 5.9814 - val_mse: 62.4741\n",
      "Epoch 343/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 39.8701 - mae: 3.5345 - mse: 39.8701 - val_loss: 28.5872 - val_mae: 3.1622 - val_mse: 28.5872\n",
      "Epoch 344/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.4114 - mae: 3.5101 - mse: 39.4114 - val_loss: 33.9104 - val_mae: 3.5349 - val_mse: 33.9104\n",
      "Epoch 345/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.2235 - mae: 3.4951 - mse: 38.2235 - val_loss: 29.3299 - val_mae: 3.2130 - val_mse: 29.3299\n",
      "Epoch 346/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 40.1057 - mae: 3.5605 - mse: 40.1057 - val_loss: 29.0328 - val_mae: 3.1607 - val_mse: 29.0328\n",
      "Epoch 347/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 39.6808 - mae: 3.5037 - mse: 39.6808 - val_loss: 33.2388 - val_mae: 3.6674 - val_mse: 33.2388\n",
      "Epoch 348/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.8567 - mae: 3.4845 - mse: 39.8568 - val_loss: 30.0931 - val_mae: 3.2978 - val_mse: 30.0931\n",
      "Epoch 349/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.1540 - mae: 3.5512 - mse: 39.1540 - val_loss: 30.5968 - val_mae: 3.1992 - val_mse: 30.5968\n",
      "Epoch 350/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1710 - mae: 3.4273 - mse: 38.1710 - val_loss: 31.1418 - val_mae: 3.2010 - val_mse: 31.1418\n",
      "Epoch 351/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.0129 - mae: 3.4239 - mse: 38.0129 - val_loss: 31.8136 - val_mae: 3.3939 - val_mse: 31.8136\n",
      "Epoch 352/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.9162 - mae: 3.4754 - mse: 38.9162 - val_loss: 28.5307 - val_mae: 3.1387 - val_mse: 28.5307\n",
      "Epoch 353/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 39.2087 - mae: 3.5414 - mse: 39.2087 - val_loss: 28.6965 - val_mae: 3.1478 - val_mse: 28.6965\n",
      "Epoch 354/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 40.2854 - mae: 3.5656 - mse: 40.2854 - val_loss: 32.2144 - val_mae: 3.4794 - val_mse: 32.2144\n",
      "Epoch 355/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 40.0054 - mae: 3.4847 - mse: 40.0055 - val_loss: 40.6607 - val_mae: 3.7310 - val_mse: 40.6607\n",
      "Epoch 356/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 40.1422 - mae: 3.5151 - mse: 40.1422 - val_loss: 31.9938 - val_mae: 3.4647 - val_mse: 31.9938\n",
      "Epoch 357/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 40.1457 - mae: 3.4986 - mse: 40.1456 - val_loss: 29.0911 - val_mae: 3.2838 - val_mse: 29.0911\n",
      "Epoch 358/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.5779 - mae: 3.4626 - mse: 39.5779 - val_loss: 29.1446 - val_mae: 3.2295 - val_mse: 29.1446\n",
      "Epoch 359/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.2303 - mae: 3.4569 - mse: 38.2303 - val_loss: 30.7585 - val_mae: 3.2782 - val_mse: 30.7585\n",
      "Epoch 360/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.6583 - mae: 3.5836 - mse: 39.6583 - val_loss: 48.8357 - val_mae: 4.8876 - val_mse: 48.8357\n",
      "Epoch 361/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 39.7106 - mae: 3.5122 - mse: 39.7106 - val_loss: 30.8448 - val_mae: 3.5818 - val_mse: 30.8448\n",
      "Epoch 362/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 39.0006 - mae: 3.4961 - mse: 39.0006 - val_loss: 34.0257 - val_mae: 3.4792 - val_mse: 34.0257\n",
      "Epoch 363/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.0344 - mae: 3.4383 - mse: 39.0345 - val_loss: 48.4064 - val_mae: 3.9838 - val_mse: 48.4064\n",
      "Epoch 364/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8581 - mae: 3.4866 - mse: 38.8581 - val_loss: 28.9573 - val_mae: 3.2302 - val_mse: 28.9573\n",
      "Epoch 365/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.3435 - mae: 3.4200 - mse: 39.3435 - val_loss: 30.5303 - val_mae: 3.3562 - val_mse: 30.5303\n",
      "Epoch 366/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 40.7164 - mae: 3.5725 - mse: 40.7164 - val_loss: 30.2924 - val_mae: 3.2897 - val_mse: 30.2924\n",
      "Epoch 367/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 39.1549 - mae: 3.4837 - mse: 39.1549 - val_loss: 30.0219 - val_mae: 3.2690 - val_mse: 30.0219\n",
      "Epoch 368/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.1431 - mae: 3.4969 - mse: 39.1431 - val_loss: 29.2182 - val_mae: 3.2251 - val_mse: 29.2182\n",
      "Epoch 369/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1257 - mae: 3.4723 - mse: 38.1258 - val_loss: 29.3482 - val_mae: 3.3752 - val_mse: 29.3482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.8440 - mae: 3.5660 - mse: 38.8440 - val_loss: 29.0954 - val_mae: 3.2282 - val_mse: 29.0954\n",
      "Epoch 371/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.4073 - mae: 3.5150 - mse: 39.4073 - val_loss: 30.9755 - val_mae: 3.4242 - val_mse: 30.9755\n",
      "Epoch 372/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 54.7120 - mae: 3.5154 - mse: 54.7120 - val_loss: 28.1775 - val_mae: 3.2362 - val_mse: 28.1775\n",
      "Epoch 373/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.1089 - mae: 3.5546 - mse: 40.1089 - val_loss: 31.1335 - val_mae: 3.2555 - val_mse: 31.1335\n",
      "Epoch 374/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.3355 - mae: 3.4513 - mse: 37.3355 - val_loss: 41.0784 - val_mae: 3.7617 - val_mse: 41.0784\n",
      "Epoch 375/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8452 - mae: 3.5125 - mse: 37.8452 - val_loss: 30.2697 - val_mae: 3.3624 - val_mse: 30.2697\n",
      "Epoch 376/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.1253 - mae: 3.4372 - mse: 38.1253 - val_loss: 32.1833 - val_mae: 3.6346 - val_mse: 32.1833\n",
      "Epoch 377/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.2372 - mae: 3.4304 - mse: 38.2372 - val_loss: 30.4179 - val_mae: 3.3368 - val_mse: 30.4179\n",
      "Epoch 378/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 40.1030 - mae: 3.5183 - mse: 40.1030 - val_loss: 28.1337 - val_mae: 3.1671 - val_mse: 28.1337\n",
      "Epoch 379/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.7478 - mae: 3.4647 - mse: 37.7478 - val_loss: 39.4555 - val_mae: 3.7742 - val_mse: 39.4555\n",
      "Epoch 380/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.7997 - mae: 3.4632 - mse: 38.7997 - val_loss: 29.9905 - val_mae: 3.2594 - val_mse: 29.9905\n",
      "Epoch 381/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5309 - mae: 3.4251 - mse: 37.5309 - val_loss: 33.7097 - val_mae: 3.6927 - val_mse: 33.7097\n",
      "Epoch 382/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.7382 - mae: 3.5293 - mse: 39.7382 - val_loss: 28.3784 - val_mae: 3.1971 - val_mse: 28.3784\n",
      "Epoch 383/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.0165 - mae: 3.4743 - mse: 39.0165 - val_loss: 29.8651 - val_mae: 3.2690 - val_mse: 29.8651\n",
      "Epoch 384/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.5272 - mae: 3.4716 - mse: 39.5272 - val_loss: 36.0375 - val_mae: 3.5236 - val_mse: 36.0375\n",
      "Epoch 385/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.4601 - mae: 3.4698 - mse: 38.4601 - val_loss: 33.1234 - val_mae: 3.4747 - val_mse: 33.1234\n",
      "Epoch 386/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.9217 - mae: 3.4788 - mse: 38.9217 - val_loss: 30.5866 - val_mae: 3.3068 - val_mse: 30.5866\n",
      "Epoch 387/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.0048 - mae: 3.4400 - mse: 39.0048 - val_loss: 29.8792 - val_mae: 3.2557 - val_mse: 29.8792\n",
      "Epoch 388/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.4349 - mae: 3.4416 - mse: 39.4349 - val_loss: 32.4775 - val_mae: 3.4209 - val_mse: 32.4775\n",
      "Epoch 389/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.5576 - mae: 3.4581 - mse: 39.5576 - val_loss: 30.6510 - val_mae: 3.2781 - val_mse: 30.6510\n",
      "Epoch 390/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.6343 - mae: 3.4865 - mse: 39.6343 - val_loss: 30.3760 - val_mae: 3.3779 - val_mse: 30.3760\n",
      "Epoch 391/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3553 - mae: 3.4935 - mse: 38.3553 - val_loss: 40.4743 - val_mae: 4.4273 - val_mse: 40.4743\n",
      "Epoch 392/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0897 - mae: 3.4760 - mse: 38.0897 - val_loss: 30.9817 - val_mae: 3.3282 - val_mse: 30.9817\n",
      "Epoch 393/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.2274 - mae: 3.4989 - mse: 39.2274 - val_loss: 28.8817 - val_mae: 3.2348 - val_mse: 28.8817\n",
      "Epoch 394/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2262 - mae: 3.4171 - mse: 38.2262 - val_loss: 29.7882 - val_mae: 3.2334 - val_mse: 29.7882\n",
      "Epoch 395/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.3458 - mae: 3.5110 - mse: 39.3458 - val_loss: 32.5004 - val_mae: 3.4255 - val_mse: 32.5004\n",
      "Epoch 396/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2168 - mae: 3.4322 - mse: 38.2168 - val_loss: 33.8855 - val_mae: 3.4082 - val_mse: 33.8855\n",
      "Epoch 397/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1328 - mae: 3.4382 - mse: 38.1329 - val_loss: 35.7195 - val_mae: 3.4179 - val_mse: 35.7195\n",
      "Epoch 398/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 41.5781 - mae: 3.5541 - mse: 41.5781 - val_loss: 34.4356 - val_mae: 3.8158 - val_mse: 34.4356\n",
      "Epoch 399/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.4079 - mae: 3.4722 - mse: 39.4079 - val_loss: 63.9893 - val_mae: 5.8990 - val_mse: 63.9893\n",
      "Epoch 400/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.9436 - mae: 3.5094 - mse: 39.9436 - val_loss: 29.0414 - val_mae: 3.2229 - val_mse: 29.0414\n",
      "Epoch 401/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5705 - mae: 3.4199 - mse: 37.5705 - val_loss: 31.5506 - val_mae: 3.4049 - val_mse: 31.5506\n",
      "Epoch 402/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.9470 - mae: 3.5118 - mse: 38.9470 - val_loss: 28.9348 - val_mae: 3.1870 - val_mse: 28.9348\n",
      "Epoch 403/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1653 - mae: 3.4119 - mse: 39.1653 - val_loss: 46.1752 - val_mae: 4.7268 - val_mse: 46.1752\n",
      "Epoch 404/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.2673 - mae: 3.4778 - mse: 40.2673 - val_loss: 31.1513 - val_mae: 3.4621 - val_mse: 31.1513\n",
      "Epoch 405/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.2981 - mae: 3.4463 - mse: 39.2981 - val_loss: 31.8219 - val_mae: 3.5401 - val_mse: 31.8219\n",
      "Epoch 406/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3410 - mae: 3.4016 - mse: 38.3410 - val_loss: 28.4635 - val_mae: 3.2156 - val_mse: 28.4635\n",
      "Epoch 407/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.5766 - mae: 3.4408 - mse: 39.5766 - val_loss: 41.8992 - val_mae: 3.8322 - val_mse: 41.8992\n",
      "Epoch 408/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8328 - mae: 3.4644 - mse: 38.8328 - val_loss: 34.4951 - val_mae: 3.5862 - val_mse: 34.4951\n",
      "Epoch 409/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.2684 - mae: 3.4462 - mse: 38.2684 - val_loss: 30.7834 - val_mae: 3.3349 - val_mse: 30.7834\n",
      "Epoch 410/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.0839 - mae: 3.4902 - mse: 39.0839 - val_loss: 34.8161 - val_mae: 3.5241 - val_mse: 34.8161\n",
      "Epoch 411/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.4148 - mae: 3.5105 - mse: 40.4149 - val_loss: 29.3409 - val_mae: 3.2769 - val_mse: 29.3409\n",
      "Epoch 412/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 39.2157 - mae: 3.4775 - mse: 39.2157 - val_loss: 34.6312 - val_mae: 3.5249 - val_mse: 34.6312\n",
      "Epoch 413/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 38.2632 - mae: 3.4480 - mse: 38.2632 - val_loss: 27.4608 - val_mae: 3.1383 - val_mse: 27.4608\n",
      "Epoch 414/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1056 - mae: 3.4143 - mse: 38.1055 - val_loss: 37.4727 - val_mae: 3.8149 - val_mse: 37.4727\n",
      "Epoch 415/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.9114 - mae: 3.4750 - mse: 38.9114 - val_loss: 40.5163 - val_mae: 3.8122 - val_mse: 40.5163\n",
      "Epoch 416/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 41.5366 - mae: 3.6193 - mse: 41.5366 - val_loss: 29.3494 - val_mae: 3.1882 - val_mse: 29.3494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.1439 - mae: 3.5014 - mse: 39.1439 - val_loss: 32.8138 - val_mae: 3.4372 - val_mse: 32.8138\n",
      "Epoch 418/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.2146 - mae: 3.4532 - mse: 38.2146 - val_loss: 54.6527 - val_mae: 4.2840 - val_mse: 54.6527\n",
      "Epoch 419/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.6464 - mae: 3.4345 - mse: 37.6465 - val_loss: 34.7774 - val_mae: 3.8408 - val_mse: 34.7774\n",
      "Epoch 420/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1177 - mae: 3.4140 - mse: 38.1176 - val_loss: 69.5849 - val_mae: 6.6253 - val_mse: 69.5849\n",
      "Epoch 421/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.3140 - mae: 3.5027 - mse: 38.3140 - val_loss: 44.5650 - val_mae: 4.7264 - val_mse: 44.5650\n",
      "Epoch 422/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9456 - mae: 3.4430 - mse: 37.9456 - val_loss: 31.0499 - val_mae: 3.3028 - val_mse: 31.0499\n",
      "Epoch 423/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1349 - mae: 3.4553 - mse: 38.1349 - val_loss: 31.8987 - val_mae: 3.3274 - val_mse: 31.8987\n",
      "Epoch 424/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.2706 - mae: 3.5122 - mse: 39.2706 - val_loss: 35.0662 - val_mae: 3.6309 - val_mse: 35.0662\n",
      "Epoch 425/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.9646 - mae: 3.4507 - mse: 38.9646 - val_loss: 31.0790 - val_mae: 3.4479 - val_mse: 31.0790\n",
      "Epoch 426/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1177 - mae: 3.5039 - mse: 38.1177 - val_loss: 40.1754 - val_mae: 4.0751 - val_mse: 40.1754\n",
      "Epoch 427/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.2279 - mae: 3.5699 - mse: 39.2279 - val_loss: 32.8592 - val_mae: 3.2670 - val_mse: 32.8592\n",
      "Epoch 428/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1859 - mae: 3.4583 - mse: 39.1859 - val_loss: 32.9564 - val_mae: 3.5534 - val_mse: 32.9564\n",
      "Epoch 429/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1824 - mae: 3.5413 - mse: 39.1824 - val_loss: 39.6654 - val_mae: 3.7646 - val_mse: 39.6654\n",
      "Epoch 430/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2785 - mae: 3.4999 - mse: 38.2785 - val_loss: 47.4287 - val_mae: 4.0773 - val_mse: 47.4287\n",
      "Epoch 431/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 41.8287 - mae: 3.5798 - mse: 41.8287 - val_loss: 30.0529 - val_mae: 3.2731 - val_mse: 30.0530\n",
      "Epoch 432/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.0048 - mae: 3.4432 - mse: 39.0048 - val_loss: 41.1344 - val_mae: 4.3436 - val_mse: 41.1344\n",
      "Epoch 433/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.3098 - mae: 3.4501 - mse: 39.3098 - val_loss: 38.2397 - val_mae: 3.8201 - val_mse: 38.2397\n",
      "Epoch 434/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 52.9978 - mae: 3.6369 - mse: 52.9978 - val_loss: 32.1498 - val_mae: 3.4052 - val_mse: 32.1498\n",
      "Epoch 435/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0835 - mae: 3.3412 - mse: 37.0835 - val_loss: 29.4207 - val_mae: 3.2284 - val_mse: 29.4207\n",
      "Epoch 436/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.5271 - mae: 3.4711 - mse: 38.5271 - val_loss: 28.2545 - val_mae: 3.2503 - val_mse: 28.2544\n",
      "Epoch 437/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 41.3466 - mae: 3.4881 - mse: 41.3465 - val_loss: 33.8360 - val_mae: 3.4785 - val_mse: 33.8360\n",
      "Epoch 438/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.2965 - mae: 3.5427 - mse: 40.2965 - val_loss: 31.3841 - val_mae: 3.3280 - val_mse: 31.3841\n",
      "Epoch 439/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.3428 - mae: 3.5872 - mse: 40.3428 - val_loss: 32.8147 - val_mae: 3.7215 - val_mse: 32.8147\n",
      "Epoch 440/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 39.7334 - mae: 3.5018 - mse: 39.7334 - val_loss: 34.6448 - val_mae: 3.4872 - val_mse: 34.6448\n",
      "Epoch 441/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.5428 - mae: 3.5075 - mse: 39.5428 - val_loss: 39.4884 - val_mae: 3.8551 - val_mse: 39.4883\n",
      "Epoch 442/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.8689 - mae: 3.5313 - mse: 39.8688 - val_loss: 34.3260 - val_mae: 3.4859 - val_mse: 34.3260\n",
      "Epoch 443/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.0964 - mae: 3.5000 - mse: 39.0964 - val_loss: 34.2329 - val_mae: 3.5218 - val_mse: 34.2329\n",
      "Epoch 444/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.8985 - mae: 3.4955 - mse: 38.8985 - val_loss: 28.9422 - val_mae: 3.2082 - val_mse: 28.9422\n",
      "Epoch 445/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.4014 - mae: 3.5258 - mse: 38.4014 - val_loss: 32.1492 - val_mae: 3.3703 - val_mse: 32.1492\n",
      "Epoch 446/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.5892 - mae: 3.4769 - mse: 38.5892 - val_loss: 52.4629 - val_mae: 4.9871 - val_mse: 52.4629\n",
      "Epoch 447/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.5654 - mae: 3.4566 - mse: 38.5654 - val_loss: 50.0125 - val_mae: 5.0016 - val_mse: 50.0125\n",
      "Epoch 448/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.5295 - mae: 3.5053 - mse: 38.5295 - val_loss: 28.5162 - val_mae: 3.3062 - val_mse: 28.5162\n",
      "Epoch 449/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.6262 - mae: 3.4783 - mse: 39.6262 - val_loss: 30.0613 - val_mae: 3.3346 - val_mse: 30.0613\n",
      "Epoch 450/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.2560 - mae: 3.5154 - mse: 39.2560 - val_loss: 30.5697 - val_mae: 3.3051 - val_mse: 30.5697\n",
      "Epoch 451/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.5249 - mae: 3.4927 - mse: 39.5249 - val_loss: 30.7355 - val_mae: 3.3627 - val_mse: 30.7355\n",
      "Epoch 452/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 40.0647 - mae: 3.5458 - mse: 40.0647 - val_loss: 29.2120 - val_mae: 3.2259 - val_mse: 29.2120\n",
      "Epoch 453/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.7480 - mae: 3.4943 - mse: 38.7480 - val_loss: 31.2219 - val_mae: 3.4063 - val_mse: 31.2219\n",
      "Epoch 454/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.2465 - mae: 3.4926 - mse: 39.2465 - val_loss: 39.7673 - val_mae: 3.6457 - val_mse: 39.7673\n",
      "Epoch 455/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.5183 - mae: 3.4808 - mse: 38.5183 - val_loss: 30.5652 - val_mae: 3.3158 - val_mse: 30.5652\n",
      "Epoch 456/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.6277 - mae: 3.5203 - mse: 38.6277 - val_loss: 33.9386 - val_mae: 3.8520 - val_mse: 33.9386\n",
      "Epoch 457/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1532 - mae: 3.4729 - mse: 39.1532 - val_loss: 28.3404 - val_mae: 3.2469 - val_mse: 28.3404\n",
      "Epoch 458/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.8616 - mae: 3.4798 - mse: 38.8616 - val_loss: 28.5797 - val_mae: 3.2715 - val_mse: 28.5797\n",
      "Epoch 459/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1290 - mae: 3.4658 - mse: 37.1290 - val_loss: 30.6952 - val_mae: 3.4534 - val_mse: 30.6952\n",
      "Epoch 460/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2024 - mae: 3.4669 - mse: 38.2024 - val_loss: 35.2138 - val_mae: 3.6338 - val_mse: 35.2138\n",
      "Epoch 461/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.4017 - mae: 3.5477 - mse: 39.4017 - val_loss: 43.2617 - val_mae: 4.3216 - val_mse: 43.2617\n",
      "Epoch 462/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 45.8764 - mae: 3.5543 - mse: 45.8765 - val_loss: 29.8694 - val_mae: 3.2242 - val_mse: 29.8694\n",
      "Epoch 463/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.8806 - mae: 3.4882 - mse: 37.8806 - val_loss: 43.2643 - val_mae: 4.2644 - val_mse: 43.2643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.4721 - mae: 3.4475 - mse: 38.4721 - val_loss: 34.9336 - val_mae: 3.8601 - val_mse: 34.9336\n",
      "Epoch 465/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.7081 - mae: 3.4735 - mse: 38.7081 - val_loss: 33.1623 - val_mae: 3.5725 - val_mse: 33.1623\n",
      "Epoch 466/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.9351 - mae: 3.5514 - mse: 39.9351 - val_loss: 38.0881 - val_mae: 3.4788 - val_mse: 38.0881\n",
      "Epoch 467/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7037 - mae: 3.3835 - mse: 37.7037 - val_loss: 37.0120 - val_mae: 3.6501 - val_mse: 37.0120\n",
      "Epoch 468/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.9238 - mae: 3.4116 - mse: 37.9238 - val_loss: 30.3624 - val_mae: 3.3643 - val_mse: 30.3624\n",
      "Epoch 469/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5402 - mae: 3.4415 - mse: 37.5402 - val_loss: 30.7790 - val_mae: 3.3170 - val_mse: 30.7790\n",
      "Epoch 470/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9188 - mae: 3.4983 - mse: 37.9188 - val_loss: 33.7043 - val_mae: 3.6633 - val_mse: 33.7043\n",
      "Epoch 471/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3175 - mae: 3.4988 - mse: 38.3175 - val_loss: 35.2617 - val_mae: 3.5076 - val_mse: 35.2617\n",
      "Epoch 472/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.9645 - mae: 3.4751 - mse: 39.9645 - val_loss: 29.0444 - val_mae: 3.2001 - val_mse: 29.0444\n",
      "Epoch 473/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3526 - mae: 3.4300 - mse: 38.3526 - val_loss: 28.9862 - val_mae: 3.2438 - val_mse: 28.9862\n",
      "Epoch 474/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1906 - mae: 3.5368 - mse: 39.1906 - val_loss: 30.0205 - val_mae: 3.3718 - val_mse: 30.0205\n",
      "Epoch 475/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.3605 - mae: 3.5165 - mse: 38.3605 - val_loss: 28.0869 - val_mae: 3.0742 - val_mse: 28.0869\n",
      "Epoch 476/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.9612 - mae: 3.5012 - mse: 38.9612 - val_loss: 30.4318 - val_mae: 3.2589 - val_mse: 30.4318\n",
      "Epoch 477/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3642 - mae: 3.4668 - mse: 38.3643 - val_loss: 104.9826 - val_mae: 8.1128 - val_mse: 104.9826\n",
      "Epoch 478/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.0199 - mae: 3.5046 - mse: 40.0199 - val_loss: 28.6519 - val_mae: 3.2808 - val_mse: 28.6519\n",
      "Epoch 479/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0293 - mae: 3.4450 - mse: 38.0293 - val_loss: 29.7532 - val_mae: 3.2237 - val_mse: 29.7532\n",
      "Epoch 480/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.6772 - mae: 3.4545 - mse: 38.6772 - val_loss: 29.2976 - val_mae: 3.2675 - val_mse: 29.2976\n",
      "Epoch 481/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.2422 - mae: 3.4518 - mse: 38.2423 - val_loss: 29.1932 - val_mae: 3.2473 - val_mse: 29.1932\n",
      "Epoch 482/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.4043 - mae: 3.3998 - mse: 38.4043 - val_loss: 29.3043 - val_mae: 3.1949 - val_mse: 29.3043\n",
      "Epoch 483/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8146 - mae: 3.4403 - mse: 38.8146 - val_loss: 33.4571 - val_mae: 3.8683 - val_mse: 33.4571\n",
      "Epoch 484/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.2864 - mae: 3.4304 - mse: 37.2864 - val_loss: 30.3676 - val_mae: 3.4422 - val_mse: 30.3676\n",
      "Epoch 485/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8617 - mae: 3.3516 - mse: 36.8617 - val_loss: 28.9526 - val_mae: 3.2174 - val_mse: 28.9526\n",
      "Epoch 486/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1640 - mae: 3.4654 - mse: 39.1640 - val_loss: 37.5092 - val_mae: 4.0105 - val_mse: 37.5092\n",
      "Epoch 487/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7973 - mae: 3.4422 - mse: 37.7973 - val_loss: 35.6890 - val_mae: 3.4347 - val_mse: 35.6890\n",
      "Epoch 488/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.3902 - mae: 3.4498 - mse: 38.3902 - val_loss: 29.2717 - val_mae: 3.2024 - val_mse: 29.2717\n",
      "Epoch 489/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.1654 - mae: 3.4614 - mse: 38.1654 - val_loss: 28.6976 - val_mae: 3.2753 - val_mse: 28.6976\n",
      "Epoch 490/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.7109 - mae: 3.5985 - mse: 39.7109 - val_loss: 86.5412 - val_mae: 6.9786 - val_mse: 86.5412\n",
      "Epoch 491/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.9718 - mae: 3.4872 - mse: 39.9718 - val_loss: 39.4061 - val_mae: 3.6706 - val_mse: 39.4061\n",
      "Epoch 492/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.5886 - mae: 3.4723 - mse: 37.5886 - val_loss: 31.1822 - val_mae: 3.4541 - val_mse: 31.1822\n",
      "Epoch 493/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1969 - mae: 3.3771 - mse: 37.1969 - val_loss: 31.7805 - val_mae: 3.6252 - val_mse: 31.7805\n",
      "Epoch 494/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.6458 - mae: 3.5253 - mse: 39.6458 - val_loss: 30.2510 - val_mae: 3.2645 - val_mse: 30.2510\n",
      "Epoch 495/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.8634 - mae: 3.4383 - mse: 37.8634 - val_loss: 30.6831 - val_mae: 3.3186 - val_mse: 30.6831\n",
      "Epoch 496/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1884 - mae: 3.4296 - mse: 38.1884 - val_loss: 33.5247 - val_mae: 3.5372 - val_mse: 33.5247\n",
      "Epoch 497/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1371 - mae: 3.4373 - mse: 38.1371 - val_loss: 30.5128 - val_mae: 3.3249 - val_mse: 30.5128\n",
      "Epoch 498/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.5587 - mae: 3.4936 - mse: 38.5587 - val_loss: 30.6921 - val_mae: 3.3156 - val_mse: 30.6921\n",
      "Epoch 499/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.9554 - mae: 3.4841 - mse: 38.9554 - val_loss: 29.1310 - val_mae: 3.3633 - val_mse: 29.1310\n",
      "Epoch 500/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.9481 - mae: 3.4405 - mse: 37.9481 - val_loss: 33.6465 - val_mae: 3.4316 - val_mse: 33.6465\n",
      "Epoch 501/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2080 - mae: 3.4413 - mse: 37.2080 - val_loss: 52.2845 - val_mae: 4.2530 - val_mse: 52.2845\n",
      "Epoch 502/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.1376 - mae: 3.4438 - mse: 37.1376 - val_loss: 37.2877 - val_mae: 3.8390 - val_mse: 37.2877\n",
      "Epoch 503/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.6423 - mae: 3.4404 - mse: 38.6423 - val_loss: 28.8715 - val_mae: 3.2484 - val_mse: 28.8715\n",
      "Epoch 504/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1069 - mae: 3.4242 - mse: 38.1069 - val_loss: 29.4686 - val_mae: 3.2647 - val_mse: 29.4686\n",
      "Epoch 505/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.8749 - mae: 3.4098 - mse: 37.8749 - val_loss: 31.2626 - val_mae: 3.4909 - val_mse: 31.2626\n",
      "Epoch 506/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.2564 - mae: 3.4505 - mse: 39.2564 - val_loss: 28.2259 - val_mae: 3.1870 - val_mse: 28.2259\n",
      "Epoch 507/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8095 - mae: 3.5174 - mse: 37.8095 - val_loss: 33.0240 - val_mae: 3.4687 - val_mse: 33.0240\n",
      "Epoch 508/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.5887 - mae: 3.4797 - mse: 38.5887 - val_loss: 40.6100 - val_mae: 4.0291 - val_mse: 40.6101\n",
      "Epoch 509/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.9064 - mae: 3.4207 - mse: 36.9064 - val_loss: 29.3676 - val_mae: 3.2407 - val_mse: 29.3676\n",
      "Epoch 510/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9090 - mae: 3.4310 - mse: 37.9090 - val_loss: 27.6688 - val_mae: 3.1830 - val_mse: 27.6688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 511/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9964 - mae: 3.3802 - mse: 36.9964 - val_loss: 35.2208 - val_mae: 3.7894 - val_mse: 35.2208\n",
      "Epoch 512/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.9154 - mae: 3.4846 - mse: 37.9154 - val_loss: 36.9226 - val_mae: 3.7412 - val_mse: 36.9226\n",
      "Epoch 513/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9838 - mae: 3.4323 - mse: 36.9838 - val_loss: 32.0955 - val_mae: 3.4000 - val_mse: 32.0955\n",
      "Epoch 514/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9100 - mae: 3.4277 - mse: 37.9100 - val_loss: 28.1436 - val_mae: 3.2769 - val_mse: 28.1436\n",
      "Epoch 515/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 38.3423 - mae: 3.5383 - mse: 38.3423 - val_loss: 31.9899 - val_mae: 3.3241 - val_mse: 31.9899\n",
      "Epoch 516/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3014 - mae: 3.4694 - mse: 38.3013 - val_loss: 35.3044 - val_mae: 3.3461 - val_mse: 35.3044\n",
      "Epoch 517/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2097 - mae: 3.4243 - mse: 37.2097 - val_loss: 28.3038 - val_mae: 3.2864 - val_mse: 28.3038\n",
      "Epoch 518/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.4398 - mae: 3.4688 - mse: 38.4398 - val_loss: 28.0783 - val_mae: 3.2346 - val_mse: 28.0783\n",
      "Epoch 519/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.0134 - mae: 3.4493 - mse: 38.0134 - val_loss: 55.0258 - val_mae: 4.6318 - val_mse: 55.0258\n",
      "Epoch 520/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.6424 - mae: 3.5888 - mse: 39.6424 - val_loss: 33.7819 - val_mae: 3.3995 - val_mse: 33.7818\n",
      "Epoch 521/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.8708 - mae: 3.4558 - mse: 37.8708 - val_loss: 29.1963 - val_mae: 3.2824 - val_mse: 29.1963\n",
      "Epoch 522/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.4158 - mae: 3.4467 - mse: 38.4158 - val_loss: 42.1948 - val_mae: 4.3857 - val_mse: 42.1948\n",
      "Epoch 523/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.5130 - mae: 3.4471 - mse: 38.5130 - val_loss: 30.7320 - val_mae: 3.4591 - val_mse: 30.7320\n",
      "Epoch 524/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5489 - mae: 3.4490 - mse: 37.5489 - val_loss: 28.0259 - val_mae: 3.1647 - val_mse: 28.0259\n",
      "Epoch 525/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.4459 - mae: 3.4373 - mse: 38.4459 - val_loss: 28.7938 - val_mae: 3.3105 - val_mse: 28.7938\n",
      "Epoch 526/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3424 - mae: 3.3879 - mse: 37.3424 - val_loss: 33.4188 - val_mae: 3.4723 - val_mse: 33.4188\n",
      "Epoch 527/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2070 - mae: 3.3970 - mse: 37.2070 - val_loss: 72.0348 - val_mae: 6.0257 - val_mse: 72.0349\n",
      "Epoch 528/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.9255 - mae: 3.4076 - mse: 38.9255 - val_loss: 36.9339 - val_mae: 3.9344 - val_mse: 36.9339\n",
      "Epoch 529/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.2263 - mae: 3.4837 - mse: 39.2263 - val_loss: 34.1998 - val_mae: 3.5406 - val_mse: 34.1998\n",
      "Epoch 530/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9400 - mae: 3.4480 - mse: 37.9400 - val_loss: 42.8972 - val_mae: 3.9532 - val_mse: 42.8972\n",
      "Epoch 531/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.6131 - mae: 3.4425 - mse: 38.6131 - val_loss: 28.2436 - val_mae: 3.1995 - val_mse: 28.2436\n",
      "Epoch 532/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2053 - mae: 3.3666 - mse: 37.2053 - val_loss: 29.1178 - val_mae: 3.2590 - val_mse: 29.1178\n",
      "Epoch 533/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4402 - mae: 3.4280 - mse: 37.4402 - val_loss: 31.8513 - val_mae: 3.4535 - val_mse: 31.8513\n",
      "Epoch 534/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 37.4581 - mae: 3.4049 - mse: 37.4581 - val_loss: 46.8153 - val_mae: 4.1388 - val_mse: 46.8153\n",
      "Epoch 535/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.5969 - mae: 3.4316 - mse: 37.5969 - val_loss: 28.9718 - val_mae: 3.2231 - val_mse: 28.9718\n",
      "Epoch 536/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.7604 - mae: 3.4198 - mse: 37.7604 - val_loss: 28.8203 - val_mae: 3.2647 - val_mse: 28.8203\n",
      "Epoch 537/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.8321 - mae: 3.4157 - mse: 36.8321 - val_loss: 28.9067 - val_mae: 3.4877 - val_mse: 28.9067\n",
      "Epoch 538/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.3477 - mae: 3.4694 - mse: 37.3477 - val_loss: 29.9334 - val_mae: 3.3089 - val_mse: 29.9334\n",
      "Epoch 539/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1018 - mae: 3.4112 - mse: 38.1018 - val_loss: 28.7088 - val_mae: 3.2389 - val_mse: 28.7088\n",
      "Epoch 540/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8539 - mae: 3.3557 - mse: 36.8539 - val_loss: 32.7907 - val_mae: 3.4941 - val_mse: 32.7907\n",
      "Epoch 541/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.0974 - mae: 3.4449 - mse: 38.0974 - val_loss: 33.0809 - val_mae: 3.6089 - val_mse: 33.0809\n",
      "Epoch 542/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3814 - mae: 3.4541 - mse: 38.3814 - val_loss: 28.5651 - val_mae: 3.3450 - val_mse: 28.5651\n",
      "Epoch 543/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4359 - mae: 3.4116 - mse: 37.4359 - val_loss: 27.3141 - val_mae: 3.2041 - val_mse: 27.3141\n",
      "Epoch 544/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.9141 - mae: 3.3515 - mse: 35.9141 - val_loss: 35.7312 - val_mae: 3.6249 - val_mse: 35.7312\n",
      "Epoch 545/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9258 - mae: 3.3924 - mse: 37.9258 - val_loss: 29.0939 - val_mae: 3.2482 - val_mse: 29.0939\n",
      "Epoch 546/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5762 - mae: 3.3747 - mse: 36.5762 - val_loss: 30.9692 - val_mae: 3.3944 - val_mse: 30.9692\n",
      "Epoch 547/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.0760 - mae: 3.3987 - mse: 37.0760 - val_loss: 29.8512 - val_mae: 3.4104 - val_mse: 29.8512\n",
      "Epoch 548/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3436 - mae: 3.4655 - mse: 37.3436 - val_loss: 28.5424 - val_mae: 3.2109 - val_mse: 28.5424\n",
      "Epoch 549/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8848 - mae: 3.5221 - mse: 38.8848 - val_loss: 32.2356 - val_mae: 3.6558 - val_mse: 32.2356\n",
      "Epoch 550/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8340 - mae: 3.4404 - mse: 38.8340 - val_loss: 36.2531 - val_mae: 3.8449 - val_mse: 36.2531\n",
      "Epoch 551/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2655 - mae: 3.3699 - mse: 36.2655 - val_loss: 38.6067 - val_mae: 3.9771 - val_mse: 38.6067\n",
      "Epoch 552/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0527 - mae: 3.4455 - mse: 38.0527 - val_loss: 30.0518 - val_mae: 3.2446 - val_mse: 30.0518\n",
      "Epoch 553/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2698 - mae: 3.4315 - mse: 38.2698 - val_loss: 28.0175 - val_mae: 3.2533 - val_mse: 28.0175\n",
      "Epoch 554/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6391 - mae: 3.4553 - mse: 37.6391 - val_loss: 33.5120 - val_mae: 3.5089 - val_mse: 33.5120\n",
      "Epoch 555/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9959 - mae: 3.4488 - mse: 37.9959 - val_loss: 30.5713 - val_mae: 3.2817 - val_mse: 30.5713\n",
      "Epoch 556/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.1026 - mae: 3.4375 - mse: 38.1026 - val_loss: 27.8256 - val_mae: 3.2556 - val_mse: 27.8256\n",
      "Epoch 557/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.7967 - mae: 3.4680 - mse: 38.7967 - val_loss: 27.9223 - val_mae: 3.2151 - val_mse: 27.9223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.7925 - mae: 3.4630 - mse: 37.7925 - val_loss: 27.4454 - val_mae: 3.1597 - val_mse: 27.4454\n",
      "Epoch 559/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.8433 - mae: 3.4825 - mse: 37.8433 - val_loss: 33.2026 - val_mae: 3.4683 - val_mse: 33.2026\n",
      "Epoch 560/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.9979 - mae: 3.3919 - mse: 36.9979 - val_loss: 40.2846 - val_mae: 3.7655 - val_mse: 40.2846\n",
      "Epoch 561/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.2619 - mae: 3.4952 - mse: 39.2619 - val_loss: 31.2717 - val_mae: 3.4794 - val_mse: 31.2717\n",
      "Epoch 562/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.6909 - mae: 3.4594 - mse: 38.6910 - val_loss: 35.2795 - val_mae: 3.6672 - val_mse: 35.2795\n",
      "Epoch 563/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0559 - mae: 3.4303 - mse: 37.0559 - val_loss: 30.3386 - val_mae: 3.3162 - val_mse: 30.3386\n",
      "Epoch 564/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.1679 - mae: 3.4654 - mse: 39.1679 - val_loss: 29.5046 - val_mae: 3.2520 - val_mse: 29.5046\n",
      "Epoch 565/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.6521 - mae: 3.4310 - mse: 37.6521 - val_loss: 30.6176 - val_mae: 3.3303 - val_mse: 30.6176\n",
      "Epoch 566/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.2490 - mae: 3.5752 - mse: 40.2490 - val_loss: 28.9792 - val_mae: 3.2230 - val_mse: 28.9792\n",
      "Epoch 567/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.4519 - mae: 3.4881 - mse: 38.4518 - val_loss: 32.8814 - val_mae: 3.6796 - val_mse: 32.8814\n",
      "Epoch 568/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0597 - mae: 3.4667 - mse: 38.0597 - val_loss: 30.6256 - val_mae: 3.3904 - val_mse: 30.6256\n",
      "Epoch 569/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.3265 - mae: 3.3706 - mse: 37.3265 - val_loss: 28.9679 - val_mae: 3.2794 - val_mse: 28.9679\n",
      "Epoch 570/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3332 - mae: 3.4527 - mse: 37.3332 - val_loss: 27.7835 - val_mae: 3.1807 - val_mse: 27.7835\n",
      "Epoch 571/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5087 - mae: 3.4278 - mse: 37.5087 - val_loss: 36.7729 - val_mae: 3.9025 - val_mse: 36.7729\n",
      "Epoch 572/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.5215 - mae: 3.4686 - mse: 38.5215 - val_loss: 65.4182 - val_mae: 5.7795 - val_mse: 65.4183\n",
      "Epoch 573/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4235 - mae: 3.4220 - mse: 37.4235 - val_loss: 29.7172 - val_mae: 3.2627 - val_mse: 29.7172\n",
      "Epoch 574/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1313 - mae: 3.4659 - mse: 38.1313 - val_loss: 29.7567 - val_mae: 3.2443 - val_mse: 29.7567\n",
      "Epoch 575/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.5570 - mae: 3.4841 - mse: 38.5570 - val_loss: 28.7014 - val_mae: 3.2747 - val_mse: 28.7014\n",
      "Epoch 576/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.8650 - mae: 3.3985 - mse: 36.8650 - val_loss: 28.8516 - val_mae: 3.2139 - val_mse: 28.8516\n",
      "Epoch 577/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.7608 - mae: 3.4267 - mse: 37.7608 - val_loss: 30.1786 - val_mae: 3.3770 - val_mse: 30.1786\n",
      "Epoch 578/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.7643 - mae: 3.4000 - mse: 36.7643 - val_loss: 31.7108 - val_mae: 3.4006 - val_mse: 31.7108\n",
      "Epoch 579/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.2069 - mae: 3.4005 - mse: 38.2069 - val_loss: 32.5148 - val_mae: 3.4405 - val_mse: 32.5148\n",
      "Epoch 580/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.4662 - mae: 3.4984 - mse: 39.4662 - val_loss: 28.5264 - val_mae: 3.2449 - val_mse: 28.5264\n",
      "Epoch 581/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.8850 - mae: 3.3639 - mse: 37.8850 - val_loss: 33.2080 - val_mae: 3.4648 - val_mse: 33.2080\n",
      "Epoch 582/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.9291 - mae: 3.4044 - mse: 37.9291 - val_loss: 29.0241 - val_mae: 3.3265 - val_mse: 29.0241\n",
      "Epoch 583/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.0207 - mae: 3.3264 - mse: 36.0207 - val_loss: 29.6740 - val_mae: 3.2974 - val_mse: 29.6740\n",
      "Epoch 584/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.3749 - mae: 3.4436 - mse: 38.3749 - val_loss: 29.1507 - val_mae: 3.2569 - val_mse: 29.1507\n",
      "Epoch 585/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4844 - mae: 3.4581 - mse: 37.4844 - val_loss: 30.4919 - val_mae: 3.2304 - val_mse: 30.4919\n",
      "Epoch 586/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.8377 - mae: 3.4632 - mse: 38.8377 - val_loss: 29.5731 - val_mae: 3.2821 - val_mse: 29.5731\n",
      "Epoch 587/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.4071 - mae: 3.3510 - mse: 37.4071 - val_loss: 41.4374 - val_mae: 3.7764 - val_mse: 41.4374\n",
      "Epoch 588/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.7209 - mae: 3.4371 - mse: 38.7209 - val_loss: 33.6152 - val_mae: 3.8045 - val_mse: 33.6152\n",
      "Epoch 589/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0010 - mae: 3.4273 - mse: 38.0010 - val_loss: 31.1435 - val_mae: 3.3827 - val_mse: 31.1435\n",
      "Epoch 590/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3691 - mae: 3.4341 - mse: 37.3691 - val_loss: 30.3998 - val_mae: 3.3184 - val_mse: 30.3998\n",
      "Epoch 591/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.7339 - mae: 3.4600 - mse: 37.7339 - val_loss: 35.5078 - val_mae: 3.4359 - val_mse: 35.5078\n",
      "Epoch 592/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.3007 - mae: 3.4604 - mse: 38.3007 - val_loss: 35.6570 - val_mae: 3.7744 - val_mse: 35.6570\n",
      "Epoch 593/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7553 - mae: 3.4577 - mse: 37.7553 - val_loss: 30.1984 - val_mae: 3.2948 - val_mse: 30.1984\n",
      "Epoch 594/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.8310 - mae: 3.3579 - mse: 36.8310 - val_loss: 41.0403 - val_mae: 4.4244 - val_mse: 41.0403\n",
      "Epoch 595/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.7998 - mae: 3.4371 - mse: 38.7998 - val_loss: 30.0858 - val_mae: 3.2899 - val_mse: 30.0858\n",
      "Epoch 596/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7679 - mae: 3.4128 - mse: 37.7679 - val_loss: 29.7020 - val_mae: 3.2350 - val_mse: 29.7020\n",
      "Epoch 597/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.4111 - mae: 3.3376 - mse: 37.4111 - val_loss: 31.3128 - val_mae: 3.3100 - val_mse: 31.3128\n",
      "Epoch 598/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.1983 - mae: 3.4138 - mse: 38.1983 - val_loss: 34.6339 - val_mae: 3.7396 - val_mse: 34.6339\n",
      "Epoch 599/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.0219 - mae: 3.4788 - mse: 40.0219 - val_loss: 32.0323 - val_mae: 3.5506 - val_mse: 32.0324\n",
      "Epoch 600/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.6029 - mae: 3.4167 - mse: 36.6029 - val_loss: 84.8710 - val_mae: 6.7484 - val_mse: 84.8710\n",
      "Epoch 601/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7708 - mae: 3.4486 - mse: 36.7707 - val_loss: 40.2602 - val_mae: 4.1772 - val_mse: 40.2602\n",
      "Epoch 602/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.5684 - mae: 3.4907 - mse: 38.5684 - val_loss: 29.2758 - val_mae: 3.2182 - val_mse: 29.2758\n",
      "Epoch 603/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1040 - mae: 3.4152 - mse: 37.1040 - val_loss: 31.2947 - val_mae: 3.3538 - val_mse: 31.2947\n",
      "Epoch 604/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4946 - mae: 3.3826 - mse: 36.4946 - val_loss: 34.5160 - val_mae: 3.8320 - val_mse: 34.5160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.9204 - mae: 3.4021 - mse: 37.9204 - val_loss: 28.0755 - val_mae: 3.2821 - val_mse: 28.0755\n",
      "Epoch 606/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5796 - mae: 3.4308 - mse: 37.5796 - val_loss: 42.9596 - val_mae: 4.9584 - val_mse: 42.9596\n",
      "Epoch 607/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4305 - mae: 3.3708 - mse: 37.4305 - val_loss: 27.4979 - val_mae: 3.2422 - val_mse: 27.4979\n",
      "Epoch 608/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2142 - mae: 3.3947 - mse: 36.2142 - val_loss: 28.9589 - val_mae: 3.2622 - val_mse: 28.9589\n",
      "Epoch 609/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1159 - mae: 3.4719 - mse: 38.1159 - val_loss: 38.1770 - val_mae: 3.8618 - val_mse: 38.1770\n",
      "Epoch 610/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.8038 - mae: 3.3965 - mse: 36.8038 - val_loss: 33.7868 - val_mae: 3.5786 - val_mse: 33.7868\n",
      "Epoch 611/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.7116 - mae: 3.3917 - mse: 36.7116 - val_loss: 104.0575 - val_mae: 8.4974 - val_mse: 104.0575\n",
      "Epoch 612/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8327 - mae: 3.4174 - mse: 37.8327 - val_loss: 31.6911 - val_mae: 3.4237 - val_mse: 31.6911\n",
      "Epoch 613/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1833 - mae: 3.4419 - mse: 38.1833 - val_loss: 27.1911 - val_mae: 3.2113 - val_mse: 27.1911\n",
      "Epoch 614/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8344 - mae: 3.3698 - mse: 36.8344 - val_loss: 32.2191 - val_mae: 3.2996 - val_mse: 32.2191\n",
      "Epoch 615/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.6275 - mae: 3.4356 - mse: 38.6275 - val_loss: 29.4344 - val_mae: 3.2994 - val_mse: 29.4344\n",
      "Epoch 616/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1011 - mae: 3.4271 - mse: 38.1011 - val_loss: 30.7573 - val_mae: 3.3004 - val_mse: 30.7573\n",
      "Epoch 617/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.6264 - mae: 3.4090 - mse: 37.6264 - val_loss: 28.1334 - val_mae: 3.1482 - val_mse: 28.1334\n",
      "Epoch 618/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.4747 - mae: 3.4250 - mse: 38.4747 - val_loss: 28.8000 - val_mae: 3.2911 - val_mse: 28.8000\n",
      "Epoch 619/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.1495 - mae: 3.4203 - mse: 38.1495 - val_loss: 30.5530 - val_mae: 3.3819 - val_mse: 30.5530\n",
      "Epoch 620/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6262 - mae: 3.4263 - mse: 37.6262 - val_loss: 33.4315 - val_mae: 3.6461 - val_mse: 33.4315\n",
      "Epoch 621/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7531 - mae: 3.3629 - mse: 36.7531 - val_loss: 33.6776 - val_mae: 3.5373 - val_mse: 33.6776\n",
      "Epoch 622/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.5471 - mae: 3.4608 - mse: 39.5471 - val_loss: 30.6946 - val_mae: 3.4251 - val_mse: 30.6946\n",
      "Epoch 623/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.0914 - mae: 3.4647 - mse: 39.0914 - val_loss: 40.5830 - val_mae: 3.7206 - val_mse: 40.5830\n",
      "Epoch 624/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.0196 - mae: 3.4856 - mse: 39.0196 - val_loss: 31.9268 - val_mae: 3.3635 - val_mse: 31.9268\n",
      "Epoch 625/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5061 - mae: 3.3652 - mse: 36.5061 - val_loss: 30.2728 - val_mae: 3.4423 - val_mse: 30.2728\n",
      "Epoch 626/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2290 - mae: 3.3546 - mse: 36.2290 - val_loss: 29.2445 - val_mae: 3.2464 - val_mse: 29.2445\n",
      "Epoch 627/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1408 - mae: 3.3959 - mse: 37.1408 - val_loss: 31.4130 - val_mae: 3.3424 - val_mse: 31.4130\n",
      "Epoch 628/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.6084 - mae: 3.4266 - mse: 37.6084 - val_loss: 28.1461 - val_mae: 3.1975 - val_mse: 28.1461\n",
      "Epoch 629/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.0752 - mae: 3.4157 - mse: 38.0752 - val_loss: 30.4720 - val_mae: 3.3300 - val_mse: 30.4720\n",
      "Epoch 630/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.0033 - mae: 3.4031 - mse: 37.0033 - val_loss: 29.4308 - val_mae: 3.3786 - val_mse: 29.4308\n",
      "Epoch 631/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.0232 - mae: 3.4585 - mse: 37.0232 - val_loss: 29.8011 - val_mae: 3.2777 - val_mse: 29.8011\n",
      "Epoch 632/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1201 - mae: 3.4139 - mse: 38.1201 - val_loss: 27.4030 - val_mae: 3.1758 - val_mse: 27.4030\n",
      "Epoch 633/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.8947 - mae: 3.3747 - mse: 36.8947 - val_loss: 32.1738 - val_mae: 3.4693 - val_mse: 32.1739\n",
      "Epoch 634/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8319 - mae: 3.4221 - mse: 36.8319 - val_loss: 29.2473 - val_mae: 3.2514 - val_mse: 29.2473\n",
      "Epoch 635/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.5827 - mae: 3.4395 - mse: 38.5827 - val_loss: 30.8892 - val_mae: 3.3869 - val_mse: 30.8892\n",
      "Epoch 636/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1619 - mae: 3.4267 - mse: 37.1619 - val_loss: 28.5235 - val_mae: 3.1524 - val_mse: 28.5235\n",
      "Epoch 637/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.5530 - mae: 3.4588 - mse: 37.5530 - val_loss: 27.9554 - val_mae: 3.1251 - val_mse: 27.9554\n",
      "Epoch 638/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8446 - mae: 3.3762 - mse: 36.8447 - val_loss: 38.4756 - val_mae: 3.8466 - val_mse: 38.4756\n",
      "Epoch 639/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.8175 - mae: 3.3945 - mse: 37.8175 - val_loss: 28.9407 - val_mae: 3.1743 - val_mse: 28.9407\n",
      "Epoch 640/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.9387 - mae: 3.5521 - mse: 38.9387 - val_loss: 35.1459 - val_mae: 3.4547 - val_mse: 35.1459\n",
      "Epoch 641/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6268 - mae: 3.4231 - mse: 37.6268 - val_loss: 38.2383 - val_mae: 3.6597 - val_mse: 38.2383\n",
      "Epoch 642/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7175 - mae: 3.4442 - mse: 37.7175 - val_loss: 60.9038 - val_mae: 5.9399 - val_mse: 60.9037\n",
      "Epoch 643/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.1467 - mae: 3.4048 - mse: 37.1467 - val_loss: 29.8534 - val_mae: 3.2758 - val_mse: 29.8534\n",
      "Epoch 644/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8501 - mae: 3.3995 - mse: 37.8501 - val_loss: 31.5200 - val_mae: 3.3103 - val_mse: 31.5200\n",
      "Epoch 645/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.2709 - mae: 3.4407 - mse: 38.2709 - val_loss: 30.4281 - val_mae: 3.3932 - val_mse: 30.4281\n",
      "Epoch 646/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.8341 - mae: 3.3671 - mse: 36.8341 - val_loss: 28.4223 - val_mae: 3.1789 - val_mse: 28.4223\n",
      "Epoch 647/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.7458 - mae: 3.3922 - mse: 37.7458 - val_loss: 31.0021 - val_mae: 3.2942 - val_mse: 31.0021\n",
      "Epoch 648/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3379 - mae: 3.4636 - mse: 38.3379 - val_loss: 32.1174 - val_mae: 3.3805 - val_mse: 32.1174\n",
      "Epoch 649/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.5018 - mae: 3.4318 - mse: 37.5018 - val_loss: 34.5564 - val_mae: 3.6994 - val_mse: 34.5564\n",
      "Epoch 650/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.1739 - mae: 3.4014 - mse: 38.1739 - val_loss: 31.7392 - val_mae: 3.3034 - val_mse: 31.7392\n",
      "Epoch 651/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8557 - mae: 3.4150 - mse: 37.8558 - val_loss: 32.1520 - val_mae: 3.3373 - val_mse: 32.1520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 652/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2657 - mae: 3.3828 - mse: 36.2657 - val_loss: 27.4736 - val_mae: 3.2196 - val_mse: 27.4736\n",
      "Epoch 653/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9097 - mae: 3.3797 - mse: 36.9097 - val_loss: 35.8738 - val_mae: 3.9775 - val_mse: 35.8738\n",
      "Epoch 654/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3137 - mae: 3.3396 - mse: 37.3137 - val_loss: 27.3246 - val_mae: 3.1746 - val_mse: 27.3246\n",
      "Epoch 655/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2219 - mae: 3.4150 - mse: 37.2219 - val_loss: 40.5806 - val_mae: 3.9156 - val_mse: 40.5806\n",
      "Epoch 656/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.7174 - mae: 3.4043 - mse: 37.7174 - val_loss: 29.1770 - val_mae: 3.2526 - val_mse: 29.1770\n",
      "Epoch 657/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.7358 - mae: 3.3364 - mse: 36.7358 - val_loss: 28.3839 - val_mae: 3.2749 - val_mse: 28.3839\n",
      "Epoch 658/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.3234 - mae: 3.3166 - mse: 35.3234 - val_loss: 48.5190 - val_mae: 4.1961 - val_mse: 48.5190\n",
      "Epoch 659/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7971 - mae: 3.4240 - mse: 37.7971 - val_loss: 29.4317 - val_mae: 3.2526 - val_mse: 29.4317\n",
      "Epoch 660/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.6601 - mae: 3.4083 - mse: 36.6601 - val_loss: 28.5900 - val_mae: 3.3159 - val_mse: 28.5900\n",
      "Epoch 661/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.3454 - mae: 3.2945 - mse: 35.3454 - val_loss: 32.4395 - val_mae: 3.6854 - val_mse: 32.4395\n",
      "Epoch 662/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8577 - mae: 3.3693 - mse: 37.8577 - val_loss: 32.8089 - val_mae: 3.4067 - val_mse: 32.8089\n",
      "Epoch 663/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0886 - mae: 3.4355 - mse: 38.0886 - val_loss: 30.6061 - val_mae: 3.2234 - val_mse: 30.6061\n",
      "Epoch 664/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5122 - mae: 3.3887 - mse: 37.5122 - val_loss: 31.1987 - val_mae: 3.3471 - val_mse: 31.1987\n",
      "Epoch 665/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.5275 - mae: 3.3831 - mse: 37.5275 - val_loss: 63.5063 - val_mae: 5.5747 - val_mse: 63.5063\n",
      "Epoch 666/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5951 - mae: 3.3463 - mse: 36.5951 - val_loss: 28.7180 - val_mae: 3.2579 - val_mse: 28.7180\n",
      "Epoch 667/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2842 - mae: 3.3959 - mse: 37.2842 - val_loss: 27.2174 - val_mae: 3.1550 - val_mse: 27.2174\n",
      "Epoch 668/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8887 - mae: 3.4245 - mse: 37.8887 - val_loss: 28.4821 - val_mae: 3.2057 - val_mse: 28.4821\n",
      "Epoch 669/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.9190 - mae: 3.4386 - mse: 36.9190 - val_loss: 29.0913 - val_mae: 3.3256 - val_mse: 29.0913\n",
      "Epoch 670/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.6869 - mae: 3.4581 - mse: 37.6869 - val_loss: 30.4569 - val_mae: 3.3725 - val_mse: 30.4569\n",
      "Epoch 671/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.3705 - mae: 3.3984 - mse: 36.3705 - val_loss: 42.0578 - val_mae: 4.0265 - val_mse: 42.0578\n",
      "Epoch 672/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8298 - mae: 3.4107 - mse: 36.8298 - val_loss: 30.2902 - val_mae: 3.3140 - val_mse: 30.2902\n",
      "Epoch 673/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.2567 - mae: 3.4716 - mse: 38.2567 - val_loss: 48.0867 - val_mae: 4.9178 - val_mse: 48.0867\n",
      "Epoch 674/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1588 - mae: 3.3529 - mse: 37.1588 - val_loss: 29.1826 - val_mae: 3.3530 - val_mse: 29.1826\n",
      "Epoch 675/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1354 - mae: 3.3748 - mse: 37.1354 - val_loss: 29.9704 - val_mae: 3.3166 - val_mse: 29.9704\n",
      "Epoch 676/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9826 - mae: 3.4905 - mse: 37.9826 - val_loss: 31.8508 - val_mae: 3.4245 - val_mse: 31.8508\n",
      "Epoch 677/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.8330 - mae: 3.3936 - mse: 37.8330 - val_loss: 28.3135 - val_mae: 3.2073 - val_mse: 28.3135\n",
      "Epoch 678/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3218 - mae: 3.3848 - mse: 37.3218 - val_loss: 28.6525 - val_mae: 3.2270 - val_mse: 28.6525\n",
      "Epoch 679/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9189 - mae: 3.3275 - mse: 36.9189 - val_loss: 30.4207 - val_mae: 3.3400 - val_mse: 30.4207\n",
      "Epoch 680/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.9721 - mae: 3.3684 - mse: 37.9721 - val_loss: 36.1904 - val_mae: 3.8004 - val_mse: 36.1904\n",
      "Epoch 681/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1911 - mae: 3.4428 - mse: 39.1911 - val_loss: 33.1366 - val_mae: 3.4537 - val_mse: 33.1366\n",
      "Epoch 682/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.1896 - mae: 3.4024 - mse: 39.1896 - val_loss: 31.5950 - val_mae: 3.4174 - val_mse: 31.5950\n",
      "Epoch 683/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3370 - mae: 3.3941 - mse: 38.3370 - val_loss: 28.0142 - val_mae: 3.1990 - val_mse: 28.0142\n",
      "Epoch 684/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2159 - mae: 3.3696 - mse: 36.2159 - val_loss: 30.0786 - val_mae: 3.3592 - val_mse: 30.0786\n",
      "Epoch 685/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0699 - mae: 3.3904 - mse: 38.0699 - val_loss: 28.6799 - val_mae: 3.2089 - val_mse: 28.6799\n",
      "Epoch 686/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.4302 - mae: 3.4819 - mse: 38.4302 - val_loss: 29.1100 - val_mae: 3.1845 - val_mse: 29.1100\n",
      "Epoch 687/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2978 - mae: 3.3513 - mse: 37.2979 - val_loss: 67.6327 - val_mae: 5.7702 - val_mse: 67.6327\n",
      "Epoch 688/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.7004 - mae: 3.3522 - mse: 36.7004 - val_loss: 48.0977 - val_mae: 4.4562 - val_mse: 48.0977\n",
      "Epoch 689/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0038 - mae: 3.3508 - mse: 37.0038 - val_loss: 29.5226 - val_mae: 3.2305 - val_mse: 29.5226\n",
      "Epoch 690/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.8634 - mae: 3.3456 - mse: 36.8634 - val_loss: 30.4431 - val_mae: 3.3980 - val_mse: 30.4431\n",
      "Epoch 691/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.0153 - mae: 3.3800 - mse: 38.0153 - val_loss: 35.2163 - val_mae: 3.4880 - val_mse: 35.2163\n",
      "Epoch 692/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.0552 - mae: 3.3849 - mse: 38.0552 - val_loss: 30.5552 - val_mae: 3.3869 - val_mse: 30.5552\n",
      "Epoch 693/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.3830 - mae: 3.3880 - mse: 38.3830 - val_loss: 30.4351 - val_mae: 3.5257 - val_mse: 30.4351\n",
      "Epoch 694/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.8653 - mae: 3.3809 - mse: 36.8653 - val_loss: 36.0786 - val_mae: 3.9592 - val_mse: 36.0786\n",
      "Epoch 695/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.6178 - mae: 3.4259 - mse: 37.6178 - val_loss: 27.7794 - val_mae: 3.2211 - val_mse: 27.7794\n",
      "Epoch 696/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0660 - mae: 3.3709 - mse: 37.0660 - val_loss: 35.2049 - val_mae: 3.7676 - val_mse: 35.2049\n",
      "Epoch 697/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.9902 - mae: 3.3982 - mse: 36.9902 - val_loss: 42.3850 - val_mae: 4.2670 - val_mse: 42.3850\n",
      "Epoch 698/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4949 - mae: 3.3752 - mse: 37.4949 - val_loss: 28.2526 - val_mae: 3.2228 - val_mse: 28.2526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.7477 - mae: 3.3638 - mse: 36.7477 - val_loss: 37.6338 - val_mae: 4.0675 - val_mse: 37.6338\n",
      "Epoch 700/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5909 - mae: 3.3603 - mse: 36.5909 - val_loss: 63.4949 - val_mae: 5.6820 - val_mse: 63.4949\n",
      "Epoch 701/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5842 - mae: 3.3902 - mse: 37.5842 - val_loss: 35.7809 - val_mae: 3.7015 - val_mse: 35.7809\n",
      "Epoch 702/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.5931 - mae: 3.4154 - mse: 37.5931 - val_loss: 29.0762 - val_mae: 3.2872 - val_mse: 29.0762\n",
      "Epoch 703/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9388 - mae: 3.4255 - mse: 37.9388 - val_loss: 30.0987 - val_mae: 3.3731 - val_mse: 30.0988\n",
      "Epoch 704/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.9109 - mae: 3.3894 - mse: 36.9109 - val_loss: 29.2609 - val_mae: 3.2607 - val_mse: 29.2609\n",
      "Epoch 705/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2435 - mae: 3.3827 - mse: 37.2435 - val_loss: 28.2645 - val_mae: 3.2728 - val_mse: 28.2645\n",
      "Epoch 706/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6351 - mae: 3.4792 - mse: 37.6351 - val_loss: 29.5847 - val_mae: 3.3909 - val_mse: 29.5847\n",
      "Epoch 707/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4272 - mae: 3.3674 - mse: 36.4272 - val_loss: 28.1789 - val_mae: 3.1887 - val_mse: 28.1789\n",
      "Epoch 708/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3718 - mae: 3.3734 - mse: 37.3718 - val_loss: 29.8098 - val_mae: 3.2090 - val_mse: 29.8098\n",
      "Epoch 709/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8447 - mae: 3.4456 - mse: 36.8447 - val_loss: 29.0908 - val_mae: 3.3142 - val_mse: 29.0908\n",
      "Epoch 710/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5766 - mae: 3.3680 - mse: 36.5766 - val_loss: 34.2418 - val_mae: 3.8737 - val_mse: 34.2418\n",
      "Epoch 711/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4796 - mae: 3.4011 - mse: 37.4796 - val_loss: 35.6028 - val_mae: 3.5695 - val_mse: 35.6028\n",
      "Epoch 712/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.1564 - mae: 3.4221 - mse: 38.1564 - val_loss: 35.2665 - val_mae: 3.5669 - val_mse: 35.2665\n",
      "Epoch 713/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8787 - mae: 3.3826 - mse: 37.8787 - val_loss: 30.7733 - val_mae: 3.2825 - val_mse: 30.7733\n",
      "Epoch 714/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.7577 - mae: 3.4530 - mse: 38.7577 - val_loss: 28.0282 - val_mae: 3.2456 - val_mse: 28.0282\n",
      "Epoch 715/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0594 - mae: 3.3758 - mse: 37.0594 - val_loss: 29.9885 - val_mae: 3.3532 - val_mse: 29.9885\n",
      "Epoch 716/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.1979 - mae: 3.3808 - mse: 37.1979 - val_loss: 33.1754 - val_mae: 3.2940 - val_mse: 33.1754\n",
      "Epoch 717/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.3632 - mae: 3.4032 - mse: 36.3632 - val_loss: 29.8970 - val_mae: 3.2526 - val_mse: 29.8970\n",
      "Epoch 718/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.4438 - mae: 3.4162 - mse: 37.4438 - val_loss: 33.9423 - val_mae: 3.5532 - val_mse: 33.9423\n",
      "Epoch 719/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.6155 - mae: 3.4399 - mse: 38.6155 - val_loss: 29.9730 - val_mae: 3.3698 - val_mse: 29.9730\n",
      "Epoch 720/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1478 - mae: 3.4135 - mse: 37.1478 - val_loss: 36.5129 - val_mae: 3.6764 - val_mse: 36.5129\n",
      "Epoch 721/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8506 - mae: 3.3731 - mse: 36.8506 - val_loss: 34.4816 - val_mae: 3.4625 - val_mse: 34.4816\n",
      "Epoch 722/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9112 - mae: 3.3549 - mse: 35.9112 - val_loss: 28.0170 - val_mae: 3.1952 - val_mse: 28.0170\n",
      "Epoch 723/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.6919 - mae: 3.3676 - mse: 37.6919 - val_loss: 38.4169 - val_mae: 3.5176 - val_mse: 38.4169\n",
      "Epoch 724/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.8841 - mae: 3.2930 - mse: 35.8841 - val_loss: 29.3327 - val_mae: 3.2336 - val_mse: 29.3327\n",
      "Epoch 725/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4823 - mae: 3.4043 - mse: 37.4823 - val_loss: 28.9037 - val_mae: 3.2333 - val_mse: 28.9037\n",
      "Epoch 726/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9862 - mae: 3.3791 - mse: 36.9862 - val_loss: 38.8198 - val_mae: 4.0205 - val_mse: 38.8198\n",
      "Epoch 727/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5079 - mae: 3.3748 - mse: 37.5080 - val_loss: 81.1958 - val_mae: 6.8961 - val_mse: 81.1958\n",
      "Epoch 728/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7261 - mae: 3.3529 - mse: 36.7261 - val_loss: 29.2058 - val_mae: 3.2230 - val_mse: 29.2058\n",
      "Epoch 729/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.0052 - mae: 3.3772 - mse: 37.0052 - val_loss: 31.6357 - val_mae: 3.2793 - val_mse: 31.6357\n",
      "Epoch 730/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.8925 - mae: 3.4308 - mse: 38.8925 - val_loss: 30.0505 - val_mae: 3.3488 - val_mse: 30.0505\n",
      "Epoch 731/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5294 - mae: 3.4740 - mse: 37.5294 - val_loss: 28.2911 - val_mae: 3.1444 - val_mse: 28.2911\n",
      "Epoch 732/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.5955 - mae: 3.3263 - mse: 36.5955 - val_loss: 38.4509 - val_mae: 3.7016 - val_mse: 38.4510\n",
      "Epoch 733/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 38.3636 - mae: 3.4233 - mse: 38.3636 - val_loss: 30.9173 - val_mae: 3.3010 - val_mse: 30.9173\n",
      "Epoch 734/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.0610 - mae: 3.3460 - mse: 36.0610 - val_loss: 89.8150 - val_mae: 7.0323 - val_mse: 89.8150\n",
      "Epoch 735/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.8136 - mae: 3.4077 - mse: 37.8136 - val_loss: 31.0251 - val_mae: 3.3398 - val_mse: 31.0251\n",
      "Epoch 736/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 36.9609 - mae: 3.3435 - mse: 36.9609 - val_loss: 30.2261 - val_mae: 3.2415 - val_mse: 30.2261\n",
      "Epoch 737/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7509 - mae: 3.4227 - mse: 37.7508 - val_loss: 30.8636 - val_mae: 3.1628 - val_mse: 30.8636\n",
      "Epoch 738/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1110 - mae: 3.3720 - mse: 37.1110 - val_loss: 29.7096 - val_mae: 3.3211 - val_mse: 29.7096\n",
      "Epoch 739/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4667 - mae: 3.3530 - mse: 37.4667 - val_loss: 29.2961 - val_mae: 3.2101 - val_mse: 29.2961\n",
      "Epoch 740/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.8498 - mae: 3.3275 - mse: 36.8498 - val_loss: 32.3762 - val_mae: 3.4028 - val_mse: 32.3762\n",
      "Epoch 741/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.4461 - mae: 3.4193 - mse: 38.4461 - val_loss: 30.2886 - val_mae: 3.3434 - val_mse: 30.2886\n",
      "Epoch 742/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.7312 - mae: 3.4351 - mse: 38.7312 - val_loss: 34.5906 - val_mae: 3.4985 - val_mse: 34.5906\n",
      "Epoch 743/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.9106 - mae: 3.4385 - mse: 38.9106 - val_loss: 31.9690 - val_mae: 3.5613 - val_mse: 31.9690\n",
      "Epoch 744/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.5147 - mae: 3.4726 - mse: 39.5147 - val_loss: 34.2901 - val_mae: 3.3104 - val_mse: 34.2901\n",
      "Epoch 745/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.5585 - mae: 3.4186 - mse: 38.5584 - val_loss: 31.3112 - val_mae: 3.3748 - val_mse: 31.3112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 746/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.3777 - mae: 3.4329 - mse: 38.3777 - val_loss: 35.2835 - val_mae: 3.4979 - val_mse: 35.2835\n",
      "Epoch 747/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0625 - mae: 3.4078 - mse: 38.0625 - val_loss: 41.8286 - val_mae: 3.8305 - val_mse: 41.8286\n",
      "Epoch 748/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.6314 - mae: 3.3411 - mse: 37.6314 - val_loss: 31.0779 - val_mae: 3.2872 - val_mse: 31.0779\n",
      "Epoch 749/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5021 - mae: 3.3736 - mse: 36.5021 - val_loss: 28.2139 - val_mae: 3.2205 - val_mse: 28.2139\n",
      "Epoch 750/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9661 - mae: 3.3483 - mse: 36.9661 - val_loss: 36.0761 - val_mae: 3.5906 - val_mse: 36.0761\n",
      "Epoch 751/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4411 - mae: 3.3068 - mse: 36.4411 - val_loss: 27.2220 - val_mae: 3.1313 - val_mse: 27.2220\n",
      "Epoch 752/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.2719 - mae: 3.2979 - mse: 36.2719 - val_loss: 45.7000 - val_mae: 4.3058 - val_mse: 45.7000\n",
      "Epoch 753/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5046 - mae: 3.3926 - mse: 37.5046 - val_loss: 41.0818 - val_mae: 3.8192 - val_mse: 41.0818\n",
      "Epoch 754/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7351 - mae: 3.3458 - mse: 36.7351 - val_loss: 31.5357 - val_mae: 3.3507 - val_mse: 31.5357\n",
      "Epoch 755/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.8762 - mae: 3.3386 - mse: 35.8761 - val_loss: 43.3955 - val_mae: 4.4012 - val_mse: 43.3955\n",
      "Epoch 756/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9712 - mae: 3.4058 - mse: 36.9712 - val_loss: 27.4667 - val_mae: 3.1466 - val_mse: 27.4667\n",
      "Epoch 757/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7637 - mae: 3.3646 - mse: 36.7637 - val_loss: 63.1943 - val_mae: 5.6449 - val_mse: 63.1943\n",
      "Epoch 758/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.0367 - mae: 3.4459 - mse: 39.0368 - val_loss: 34.0514 - val_mae: 3.3642 - val_mse: 34.0514\n",
      "Epoch 759/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.3333 - mae: 3.3234 - mse: 36.3333 - val_loss: 30.7521 - val_mae: 3.3180 - val_mse: 30.7521\n",
      "Epoch 760/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.0616 - mae: 3.4586 - mse: 38.0616 - val_loss: 28.3301 - val_mae: 3.3908 - val_mse: 28.3301\n",
      "Epoch 761/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.3471 - mae: 3.4221 - mse: 37.3471 - val_loss: 27.7578 - val_mae: 3.1938 - val_mse: 27.7578\n",
      "Epoch 762/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.0651 - mae: 3.3202 - mse: 36.0651 - val_loss: 36.1403 - val_mae: 3.5825 - val_mse: 36.1403\n",
      "Epoch 763/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.6554 - mae: 3.3699 - mse: 36.6554 - val_loss: 31.1166 - val_mae: 3.4502 - val_mse: 31.1167\n",
      "Epoch 764/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2195 - mae: 3.4008 - mse: 37.2195 - val_loss: 28.7102 - val_mae: 3.2966 - val_mse: 28.7102\n",
      "Epoch 765/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4409 - mae: 3.3623 - mse: 37.4409 - val_loss: 34.8521 - val_mae: 3.4809 - val_mse: 34.8521\n",
      "Epoch 766/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.4492 - mae: 3.3799 - mse: 36.4492 - val_loss: 32.4367 - val_mae: 3.5576 - val_mse: 32.4367\n",
      "Epoch 767/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.9594 - mae: 3.4427 - mse: 36.9594 - val_loss: 43.5963 - val_mae: 3.8061 - val_mse: 43.5963\n",
      "Epoch 768/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9506 - mae: 3.3538 - mse: 37.9506 - val_loss: 30.1106 - val_mae: 3.3137 - val_mse: 30.1106\n",
      "Epoch 769/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.3009 - mae: 3.3811 - mse: 36.3009 - val_loss: 28.6513 - val_mae: 3.2213 - val_mse: 28.6513\n",
      "Epoch 770/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.4384 - mae: 3.3142 - mse: 36.4384 - val_loss: 28.4767 - val_mae: 3.1850 - val_mse: 28.4767\n",
      "Epoch 771/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.8162 - mae: 3.3947 - mse: 37.8161 - val_loss: 34.0497 - val_mae: 3.4446 - val_mse: 34.0497\n",
      "Epoch 772/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5553 - mae: 3.3707 - mse: 37.5553 - val_loss: 27.3205 - val_mae: 3.1841 - val_mse: 27.3205\n",
      "Epoch 773/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 35.8862 - mae: 3.3189 - mse: 35.8862 - val_loss: 30.4074 - val_mae: 3.3085 - val_mse: 30.4074\n",
      "Epoch 774/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9614 - mae: 3.3223 - mse: 35.9614 - val_loss: 29.0268 - val_mae: 3.1463 - val_mse: 29.0268\n",
      "Epoch 775/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4282 - mae: 3.3671 - mse: 36.4282 - val_loss: 29.2697 - val_mae: 3.2354 - val_mse: 29.2697\n",
      "Epoch 776/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.9656 - mae: 3.3482 - mse: 36.9656 - val_loss: 28.9266 - val_mae: 3.2941 - val_mse: 28.9266\n",
      "Epoch 777/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 36.5685 - mae: 3.2919 - mse: 36.5685 - val_loss: 32.7921 - val_mae: 3.4162 - val_mse: 32.7921\n",
      "Epoch 778/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 40.4285 - mae: 3.3452 - mse: 40.4285 - val_loss: 42.4967 - val_mae: 3.8409 - val_mse: 42.4967\n",
      "Epoch 779/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9151 - mae: 3.3933 - mse: 36.9151 - val_loss: 27.2467 - val_mae: 3.1308 - val_mse: 27.2467\n",
      "Epoch 780/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2549 - mae: 3.3037 - mse: 36.2549 - val_loss: 57.2061 - val_mae: 5.4499 - val_mse: 57.2061\n",
      "Epoch 781/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3772 - mae: 3.3872 - mse: 37.3772 - val_loss: 35.8585 - val_mae: 3.5412 - val_mse: 35.8585\n",
      "Epoch 782/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.6739 - mae: 3.3239 - mse: 36.6739 - val_loss: 33.7761 - val_mae: 3.6276 - val_mse: 33.7761\n",
      "Epoch 783/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.2101 - mae: 3.3681 - mse: 37.2101 - val_loss: 38.5881 - val_mae: 3.6723 - val_mse: 38.5881\n",
      "Epoch 784/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5545 - mae: 3.4117 - mse: 37.5545 - val_loss: 33.4189 - val_mae: 3.7790 - val_mse: 33.4189\n",
      "Epoch 785/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7808 - mae: 3.3806 - mse: 37.7808 - val_loss: 29.4580 - val_mae: 3.1203 - val_mse: 29.4580\n",
      "Epoch 786/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4673 - mae: 3.3596 - mse: 37.4673 - val_loss: 29.0873 - val_mae: 3.2358 - val_mse: 29.0873\n",
      "Epoch 787/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.0352 - mae: 3.3174 - mse: 36.0352 - val_loss: 41.9851 - val_mae: 4.4646 - val_mse: 41.9851\n",
      "Epoch 788/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4144 - mae: 3.4394 - mse: 37.4144 - val_loss: 28.4696 - val_mae: 3.2726 - val_mse: 28.4696\n",
      "Epoch 789/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4111 - mae: 3.3803 - mse: 37.4111 - val_loss: 28.3756 - val_mae: 3.2110 - val_mse: 28.3756\n",
      "Epoch 790/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.9822 - mae: 3.3616 - mse: 35.9822 - val_loss: 29.3118 - val_mae: 3.4222 - val_mse: 29.3118\n",
      "Epoch 791/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9703 - mae: 3.3605 - mse: 36.9703 - val_loss: 32.0117 - val_mae: 3.5975 - val_mse: 32.0117\n",
      "Epoch 792/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.2342 - mae: 3.3283 - mse: 36.2342 - val_loss: 28.6951 - val_mae: 3.2286 - val_mse: 28.6951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9836 - mae: 3.3736 - mse: 35.9836 - val_loss: 33.7080 - val_mae: 3.4923 - val_mse: 33.7080\n",
      "Epoch 794/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.3344 - mae: 3.3484 - mse: 36.3344 - val_loss: 42.1042 - val_mae: 4.2005 - val_mse: 42.1042\n",
      "Epoch 795/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.7344 - mae: 3.3560 - mse: 36.7344 - val_loss: 36.2184 - val_mae: 3.5452 - val_mse: 36.2184\n",
      "Epoch 796/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4448 - mae: 3.3187 - mse: 37.4448 - val_loss: 95.4506 - val_mae: 7.6280 - val_mse: 95.4506\n",
      "Epoch 797/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.1166 - mae: 3.3809 - mse: 37.1166 - val_loss: 27.4809 - val_mae: 3.1514 - val_mse: 27.4809\n",
      "Epoch 798/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2614 - mae: 3.3227 - mse: 36.2614 - val_loss: 40.8397 - val_mae: 3.8183 - val_mse: 40.8397\n",
      "Epoch 799/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6560 - mae: 3.4135 - mse: 37.6560 - val_loss: 29.5760 - val_mae: 3.3464 - val_mse: 29.5760\n",
      "Epoch 800/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.0460 - mae: 3.2612 - mse: 35.0460 - val_loss: 27.8554 - val_mae: 3.1473 - val_mse: 27.8554\n",
      "Epoch 801/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9936 - mae: 3.2979 - mse: 35.9936 - val_loss: 90.0510 - val_mae: 7.2620 - val_mse: 90.0510\n",
      "Epoch 802/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9631 - mae: 3.3339 - mse: 35.9631 - val_loss: 31.6267 - val_mae: 3.2877 - val_mse: 31.6267\n",
      "Epoch 803/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.4006 - mae: 3.3209 - mse: 37.4006 - val_loss: 38.1011 - val_mae: 3.4815 - val_mse: 38.1011\n",
      "Epoch 804/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0952 - mae: 3.3369 - mse: 37.0952 - val_loss: 65.7686 - val_mae: 5.9292 - val_mse: 65.7686\n",
      "Epoch 805/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.8266 - mae: 3.3167 - mse: 35.8266 - val_loss: 27.9595 - val_mae: 3.1564 - val_mse: 27.9595\n",
      "Epoch 806/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4429 - mae: 3.3414 - mse: 37.4429 - val_loss: 28.6718 - val_mae: 3.1682 - val_mse: 28.6718\n",
      "Epoch 807/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.5525 - mae: 3.3154 - mse: 35.5525 - val_loss: 28.1301 - val_mae: 3.1363 - val_mse: 28.1301\n",
      "Epoch 808/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7681 - mae: 3.3529 - mse: 37.7681 - val_loss: 28.4878 - val_mae: 3.1389 - val_mse: 28.4878\n",
      "Epoch 809/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.7042 - mae: 3.3350 - mse: 36.7042 - val_loss: 28.3430 - val_mae: 3.1982 - val_mse: 28.3430\n",
      "Epoch 810/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.3545 - mae: 3.2649 - mse: 36.3545 - val_loss: 72.8902 - val_mae: 6.2824 - val_mse: 72.8902\n",
      "Epoch 811/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2285 - mae: 3.4671 - mse: 38.2285 - val_loss: 29.8398 - val_mae: 3.2462 - val_mse: 29.8398\n",
      "Epoch 812/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.3673 - mae: 3.3072 - mse: 36.3673 - val_loss: 35.7897 - val_mae: 3.6773 - val_mse: 35.7897\n",
      "Epoch 813/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.5195 - mae: 3.3345 - mse: 36.5195 - val_loss: 31.3392 - val_mae: 3.6078 - val_mse: 31.3392\n",
      "Epoch 814/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9733 - mae: 3.3402 - mse: 35.9733 - val_loss: 27.7232 - val_mae: 3.2175 - val_mse: 27.7232\n",
      "Epoch 815/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6668 - mae: 3.3984 - mse: 37.6668 - val_loss: 27.1411 - val_mae: 3.1883 - val_mse: 27.1411\n",
      "Epoch 816/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9822 - mae: 3.2757 - mse: 35.9822 - val_loss: 29.3490 - val_mae: 3.2463 - val_mse: 29.3490\n",
      "Epoch 817/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.1906 - mae: 3.3065 - mse: 36.1906 - val_loss: 38.9309 - val_mae: 4.1501 - val_mse: 38.9309\n",
      "Epoch 818/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.4609 - mae: 3.3273 - mse: 36.4609 - val_loss: 28.0843 - val_mae: 3.1629 - val_mse: 28.0843\n",
      "Epoch 819/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1992 - mae: 3.3350 - mse: 37.1992 - val_loss: 29.0981 - val_mae: 3.2970 - val_mse: 29.0981\n",
      "Epoch 820/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.8614 - mae: 3.3260 - mse: 35.8614 - val_loss: 31.9739 - val_mae: 3.5322 - val_mse: 31.9739\n",
      "Epoch 821/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 36.0639 - mae: 3.3045 - mse: 36.0639 - val_loss: 28.2842 - val_mae: 3.2874 - val_mse: 28.2842\n",
      "Epoch 822/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.5854 - mae: 3.2964 - mse: 35.5854 - val_loss: 29.7547 - val_mae: 3.1919 - val_mse: 29.7547\n",
      "Epoch 823/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.3215 - mae: 3.3139 - mse: 37.3215 - val_loss: 29.1427 - val_mae: 3.2264 - val_mse: 29.1427\n",
      "Epoch 824/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.1852 - mae: 3.3222 - mse: 36.1852 - val_loss: 39.7242 - val_mae: 4.0377 - val_mse: 39.7242\n",
      "Epoch 825/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.1682 - mae: 3.3840 - mse: 37.1682 - val_loss: 28.9935 - val_mae: 3.2289 - val_mse: 28.9935\n",
      "Epoch 826/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.6726 - mae: 3.4082 - mse: 37.6726 - val_loss: 42.9475 - val_mae: 4.2530 - val_mse: 42.9475\n",
      "Epoch 827/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.0722 - mae: 3.3158 - mse: 36.0722 - val_loss: 28.4530 - val_mae: 3.2033 - val_mse: 28.4530\n",
      "Epoch 828/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.4372 - mae: 3.3054 - mse: 36.4372 - val_loss: 34.3993 - val_mae: 3.5490 - val_mse: 34.3993\n",
      "Epoch 829/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5169 - mae: 3.3475 - mse: 37.5169 - val_loss: 29.3644 - val_mae: 3.1910 - val_mse: 29.3644\n",
      "Epoch 830/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2793 - mae: 3.3439 - mse: 36.2793 - val_loss: 29.4208 - val_mae: 3.2244 - val_mse: 29.4208\n",
      "Epoch 831/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4372 - mae: 3.3929 - mse: 37.4372 - val_loss: 35.9353 - val_mae: 3.5886 - val_mse: 35.9353\n",
      "Epoch 832/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.3981 - mae: 3.3620 - mse: 37.3981 - val_loss: 29.1854 - val_mae: 3.1664 - val_mse: 29.1854\n",
      "Epoch 833/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.7890 - mae: 3.2840 - mse: 35.7890 - val_loss: 28.8252 - val_mae: 3.1167 - val_mse: 28.8252\n",
      "Epoch 834/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1419 - mae: 3.3221 - mse: 37.1419 - val_loss: 35.8225 - val_mae: 3.9137 - val_mse: 35.8225\n",
      "Epoch 835/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9635 - mae: 3.3427 - mse: 36.9635 - val_loss: 31.0394 - val_mae: 3.2819 - val_mse: 31.0394\n",
      "Epoch 836/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.2398 - mae: 3.3412 - mse: 37.2398 - val_loss: 30.5548 - val_mae: 3.2146 - val_mse: 30.5548\n",
      "Epoch 837/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.5770 - mae: 3.5077 - mse: 38.5770 - val_loss: 28.3502 - val_mae: 3.2489 - val_mse: 28.3502\n",
      "Epoch 838/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.4781 - mae: 3.3491 - mse: 35.4781 - val_loss: 27.1773 - val_mae: 3.1611 - val_mse: 27.1773\n",
      "Epoch 839/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.6015 - mae: 3.3766 - mse: 36.6015 - val_loss: 29.1494 - val_mae: 3.2195 - val_mse: 29.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.8634 - mae: 3.3434 - mse: 35.8634 - val_loss: 32.3687 - val_mae: 3.3047 - val_mse: 32.3687\n",
      "Epoch 841/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5508 - mae: 3.3577 - mse: 36.5508 - val_loss: 30.1747 - val_mae: 3.3760 - val_mse: 30.1747\n",
      "Epoch 842/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.0970 - mae: 3.3924 - mse: 38.0970 - val_loss: 28.5575 - val_mae: 3.2509 - val_mse: 28.5575\n",
      "Epoch 843/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.0496 - mae: 3.3624 - mse: 37.0496 - val_loss: 31.6462 - val_mae: 3.4319 - val_mse: 31.6462\n",
      "Epoch 844/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.3713 - mae: 3.4168 - mse: 37.3713 - val_loss: 34.4447 - val_mae: 3.4135 - val_mse: 34.4447\n",
      "Epoch 845/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.7418 - mae: 3.4540 - mse: 38.7418 - val_loss: 28.0077 - val_mae: 3.1944 - val_mse: 28.0077\n",
      "Epoch 846/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4897 - mae: 3.4349 - mse: 36.4897 - val_loss: 27.4501 - val_mae: 3.1682 - val_mse: 27.4501\n",
      "Epoch 847/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0540 - mae: 3.4222 - mse: 38.0540 - val_loss: 36.0177 - val_mae: 4.2067 - val_mse: 36.0177\n",
      "Epoch 848/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8646 - mae: 3.4623 - mse: 38.8646 - val_loss: 31.2808 - val_mae: 3.4715 - val_mse: 31.2808\n",
      "Epoch 849/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.9265 - mae: 3.3699 - mse: 36.9265 - val_loss: 29.4832 - val_mae: 3.3415 - val_mse: 29.4832\n",
      "Epoch 850/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.8091 - mae: 3.3163 - mse: 35.8091 - val_loss: 32.6943 - val_mae: 3.5478 - val_mse: 32.6943\n",
      "Epoch 851/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7716 - mae: 3.3341 - mse: 36.7716 - val_loss: 33.6182 - val_mae: 3.5675 - val_mse: 33.6182\n",
      "Epoch 852/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 36.0358 - mae: 3.3299 - mse: 36.0358 - val_loss: 32.5160 - val_mae: 3.3260 - val_mse: 32.5160\n",
      "Epoch 853/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 37.1362 - mae: 3.3723 - mse: 37.1362 - val_loss: 27.3394 - val_mae: 3.1844 - val_mse: 27.3394\n",
      "Epoch 854/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 37.6557 - mae: 3.4278 - mse: 37.6557 - val_loss: 28.9237 - val_mae: 3.2337 - val_mse: 28.9237\n",
      "Epoch 855/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8317 - mae: 3.3511 - mse: 36.8317 - val_loss: 30.8756 - val_mae: 3.3768 - val_mse: 30.8756\n",
      "Epoch 856/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7290 - mae: 3.3508 - mse: 36.7290 - val_loss: 32.5250 - val_mae: 3.3660 - val_mse: 32.5250\n",
      "Epoch 857/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.5236 - mae: 3.3207 - mse: 36.5236 - val_loss: 28.1197 - val_mae: 3.2178 - val_mse: 28.1197\n",
      "Epoch 858/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.3223 - mae: 3.3680 - mse: 36.3223 - val_loss: 44.9506 - val_mae: 3.7789 - val_mse: 44.9506\n",
      "Epoch 859/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.2124 - mae: 3.4313 - mse: 37.2124 - val_loss: 33.0716 - val_mae: 3.4364 - val_mse: 33.0716\n",
      "Epoch 860/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3636 - mae: 3.4126 - mse: 37.3636 - val_loss: 33.3542 - val_mae: 3.5815 - val_mse: 33.3542\n",
      "Epoch 861/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.6810 - mae: 3.3819 - mse: 36.6811 - val_loss: 29.2384 - val_mae: 3.2422 - val_mse: 29.2384\n",
      "Epoch 862/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.1113 - mae: 3.3562 - mse: 36.1113 - val_loss: 30.5835 - val_mae: 3.3350 - val_mse: 30.5835\n",
      "Epoch 863/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.6262 - mae: 3.3836 - mse: 37.6262 - val_loss: 28.7984 - val_mae: 3.3947 - val_mse: 28.7984\n",
      "Epoch 864/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.8223 - mae: 3.3386 - mse: 36.8223 - val_loss: 29.7680 - val_mae: 3.3542 - val_mse: 29.7680\n",
      "Epoch 865/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.0829 - mae: 3.4128 - mse: 37.0829 - val_loss: 29.7414 - val_mae: 3.3931 - val_mse: 29.7414\n",
      "Epoch 866/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4029 - mae: 3.4228 - mse: 37.4029 - val_loss: 28.0655 - val_mae: 3.2140 - val_mse: 28.0655\n",
      "Epoch 867/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 37.2159 - mae: 3.4561 - mse: 37.2159 - val_loss: 29.0740 - val_mae: 3.2729 - val_mse: 29.0740\n",
      "Epoch 868/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.4236 - mae: 3.3562 - mse: 37.4236 - val_loss: 37.2001 - val_mae: 3.5186 - val_mse: 37.2001\n",
      "Epoch 869/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.3661 - mae: 3.3485 - mse: 36.3662 - val_loss: 44.1287 - val_mae: 3.9465 - val_mse: 44.1287\n",
      "Epoch 870/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.3314 - mae: 3.3517 - mse: 37.3314 - val_loss: 29.0249 - val_mae: 3.3302 - val_mse: 29.0249\n",
      "Epoch 871/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.2917 - mae: 3.3590 - mse: 36.2917 - val_loss: 30.8059 - val_mae: 3.2668 - val_mse: 30.8059\n",
      "Epoch 872/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.6330 - mae: 3.3375 - mse: 36.6330 - val_loss: 31.7588 - val_mae: 3.2844 - val_mse: 31.7588\n",
      "Epoch 873/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 38.0256 - mae: 3.4156 - mse: 38.0256 - val_loss: 28.3106 - val_mae: 3.1988 - val_mse: 28.3106\n",
      "Epoch 874/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1996 - mae: 3.3932 - mse: 37.1996 - val_loss: 46.0714 - val_mae: 4.2831 - val_mse: 46.0714\n",
      "Epoch 875/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 37.1854 - mae: 3.3833 - mse: 37.1853 - val_loss: 31.7579 - val_mae: 3.7074 - val_mse: 31.7579\n",
      "Epoch 876/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4431 - mae: 3.3499 - mse: 36.4431 - val_loss: 32.0787 - val_mae: 3.2848 - val_mse: 32.0787\n",
      "Epoch 877/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 36.3137 - mae: 3.3351 - mse: 36.3137 - val_loss: 32.3563 - val_mae: 3.6267 - val_mse: 32.3563\n",
      "Epoch 878/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.5798 - mae: 3.3311 - mse: 36.5798 - val_loss: 29.5681 - val_mae: 3.2845 - val_mse: 29.5681\n",
      "Epoch 879/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 35.8517 - mae: 3.3277 - mse: 35.8517 - val_loss: 28.9290 - val_mae: 3.2233 - val_mse: 28.9290\n",
      "Epoch 880/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.8934 - mae: 3.3517 - mse: 35.8934 - val_loss: 29.3417 - val_mae: 3.2033 - val_mse: 29.3417\n",
      "Epoch 881/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7550 - mae: 3.3593 - mse: 36.7550 - val_loss: 29.0833 - val_mae: 3.2317 - val_mse: 29.0833\n",
      "Epoch 882/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.9117 - mae: 3.3744 - mse: 37.9117 - val_loss: 37.6171 - val_mae: 3.6688 - val_mse: 37.6171\n",
      "Epoch 883/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 38.1049 - mae: 3.4298 - mse: 38.1049 - val_loss: 30.5736 - val_mae: 3.2640 - val_mse: 30.5736\n",
      "Epoch 884/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2828 - mae: 3.3787 - mse: 36.2828 - val_loss: 31.7140 - val_mae: 3.3677 - val_mse: 31.7140\n",
      "Epoch 885/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 37.4867 - mae: 3.3911 - mse: 37.4867 - val_loss: 35.5135 - val_mae: 3.5789 - val_mse: 35.5135\n",
      "Epoch 886/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.9856 - mae: 3.3506 - mse: 35.9856 - val_loss: 31.3119 - val_mae: 3.3170 - val_mse: 31.3119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.5747 - mae: 3.4695 - mse: 37.5747 - val_loss: 29.8216 - val_mae: 3.2262 - val_mse: 29.8216\n",
      "Epoch 888/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2936 - mae: 3.3431 - mse: 37.2936 - val_loss: 36.2200 - val_mae: 3.5290 - val_mse: 36.2200\n",
      "Epoch 889/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.2988 - mae: 3.3608 - mse: 37.2988 - val_loss: 30.1707 - val_mae: 3.3119 - val_mse: 30.1707\n",
      "Epoch 890/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.4874 - mae: 3.3786 - mse: 37.4874 - val_loss: 32.6593 - val_mae: 3.4150 - val_mse: 32.6593\n",
      "Epoch 891/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 35.7275 - mae: 3.3055 - mse: 35.7275 - val_loss: 30.1899 - val_mae: 3.2516 - val_mse: 30.1899\n",
      "Epoch 892/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 37.3418 - mae: 3.3340 - mse: 37.3418 - val_loss: 31.2847 - val_mae: 3.3215 - val_mse: 31.2847\n",
      "Epoch 893/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 36.7919 - mae: 3.3657 - mse: 36.7919 - val_loss: 29.9446 - val_mae: 3.2580 - val_mse: 29.9446\n",
      "Epoch 894/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 37.9184 - mae: 3.3523 - mse: 37.9184 - val_loss: 27.8617 - val_mae: 3.2445 - val_mse: 27.8617\n",
      "Epoch 895/1000\n",
      "3852/3852 [==============================] - 0s 41us/step - loss: 37.0780 - mae: 3.4005 - mse: 37.0780 - val_loss: 28.8269 - val_mae: 3.2913 - val_mse: 28.8269\n",
      "Epoch 896/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 36.4535 - mae: 3.3820 - mse: 36.4535 - val_loss: 33.5268 - val_mae: 3.5678 - val_mse: 33.5268\n",
      "Epoch 897/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.1354 - mae: 3.3819 - mse: 37.1354 - val_loss: 30.0466 - val_mae: 3.4621 - val_mse: 30.0466\n",
      "Epoch 898/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 35.9377 - mae: 3.3547 - mse: 35.9377 - val_loss: 29.4398 - val_mae: 3.2542 - val_mse: 29.4398\n",
      "Epoch 899/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 36.6742 - mae: 3.3511 - mse: 36.6742 - val_loss: 42.9616 - val_mae: 3.9750 - val_mse: 42.9616\n",
      "Epoch 900/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 35.9680 - mae: 3.3238 - mse: 35.9680 - val_loss: 35.1718 - val_mae: 3.8424 - val_mse: 35.1718\n",
      "Epoch 901/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.0873 - mae: 3.4840 - mse: 38.0873 - val_loss: 39.0097 - val_mae: 3.7182 - val_mse: 39.0097\n",
      "Epoch 902/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 39.3247 - mae: 3.5635 - mse: 39.3247 - val_loss: 30.4477 - val_mae: 3.5021 - val_mse: 30.4477\n",
      "Epoch 903/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 37.9057 - mae: 3.5217 - mse: 37.9057 - val_loss: 40.0911 - val_mae: 3.8866 - val_mse: 40.0911\n",
      "Epoch 904/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4268 - mae: 3.3398 - mse: 36.4268 - val_loss: 27.9000 - val_mae: 3.1938 - val_mse: 27.9000\n",
      "Epoch 905/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.8639 - mae: 3.3738 - mse: 36.8639 - val_loss: 30.9572 - val_mae: 3.3333 - val_mse: 30.9572\n",
      "Epoch 906/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 36.2781 - mae: 3.3231 - mse: 36.2781 - val_loss: 30.0897 - val_mae: 3.3400 - val_mse: 30.0897\n",
      "Epoch 907/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4559 - mae: 3.3341 - mse: 36.4559 - val_loss: 29.8322 - val_mae: 3.3488 - val_mse: 29.8322\n",
      "Epoch 908/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7376 - mae: 3.3344 - mse: 36.7376 - val_loss: 32.7692 - val_mae: 3.4689 - val_mse: 32.7692\n",
      "Epoch 909/1000\n",
      "3852/3852 [==============================] - 0s 32us/step - loss: 36.5169 - mae: 3.3820 - mse: 36.5169 - val_loss: 32.7587 - val_mae: 3.3369 - val_mse: 32.7587\n",
      "Epoch 910/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.3142 - mae: 3.3570 - mse: 36.3142 - val_loss: 34.9406 - val_mae: 3.5731 - val_mse: 34.9406\n",
      "Epoch 911/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.2135 - mae: 3.3395 - mse: 36.2135 - val_loss: 32.0834 - val_mae: 3.4491 - val_mse: 32.0834\n",
      "Epoch 912/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 36.9144 - mae: 3.3763 - mse: 36.9144 - val_loss: 31.6460 - val_mae: 3.2914 - val_mse: 31.6460\n",
      "Epoch 913/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 37.3427 - mae: 3.4052 - mse: 37.3427 - val_loss: 48.7160 - val_mae: 4.2152 - val_mse: 48.7160\n",
      "Epoch 914/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 35.5369 - mae: 3.3342 - mse: 35.5369 - val_loss: 30.9778 - val_mae: 3.2151 - val_mse: 30.9778\n",
      "Epoch 915/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.9698 - mae: 3.4792 - mse: 38.9698 - val_loss: 38.7861 - val_mae: 3.5846 - val_mse: 38.7861\n",
      "Epoch 916/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0313 - mae: 3.3689 - mse: 37.0313 - val_loss: 50.5784 - val_mae: 4.3020 - val_mse: 50.5784\n",
      "Epoch 917/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 37.2550 - mae: 3.3592 - mse: 37.2550 - val_loss: 35.0721 - val_mae: 3.3661 - val_mse: 35.0721\n",
      "Epoch 918/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.7453 - mae: 3.3337 - mse: 36.7453 - val_loss: 35.1385 - val_mae: 3.2918 - val_mse: 35.1385\n",
      "Epoch 919/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7495 - mae: 3.4129 - mse: 37.7495 - val_loss: 40.6329 - val_mae: 3.5224 - val_mse: 40.6329\n",
      "Epoch 920/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.7907 - mae: 3.3670 - mse: 36.7907 - val_loss: 36.1173 - val_mae: 3.3368 - val_mse: 36.1173\n",
      "Epoch 921/1000\n",
      "3852/3852 [==============================] - 0s 37us/step - loss: 36.7395 - mae: 3.3414 - mse: 36.7395 - val_loss: 38.5992 - val_mae: 3.5244 - val_mse: 38.5992\n",
      "Epoch 922/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.8043 - mae: 3.3320 - mse: 36.8043 - val_loss: 37.2615 - val_mae: 3.4520 - val_mse: 37.2615\n",
      "Epoch 923/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4093 - mae: 3.3401 - mse: 36.4093 - val_loss: 35.4353 - val_mae: 3.3318 - val_mse: 35.4353\n",
      "Epoch 924/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.7633 - mae: 3.3425 - mse: 35.7633 - val_loss: 37.7195 - val_mae: 3.3924 - val_mse: 37.7195\n",
      "Epoch 925/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5170 - mae: 3.3533 - mse: 36.5170 - val_loss: 30.7455 - val_mae: 3.2729 - val_mse: 30.7455\n",
      "Epoch 926/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 36.9330 - mae: 3.3679 - mse: 36.9330 - val_loss: 42.0959 - val_mae: 3.6900 - val_mse: 42.0959\n",
      "Epoch 927/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.5631 - mae: 3.3113 - mse: 36.5632 - val_loss: 35.8279 - val_mae: 3.3474 - val_mse: 35.8279\n",
      "Epoch 928/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 37.7945 - mae: 3.3556 - mse: 37.7945 - val_loss: 53.9510 - val_mae: 4.5099 - val_mse: 53.9510\n",
      "Epoch 929/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.8360 - mae: 3.3555 - mse: 36.8360 - val_loss: 65.2461 - val_mae: 5.6101 - val_mse: 65.2461\n",
      "Epoch 930/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 35.1571 - mae: 3.2802 - mse: 35.1571 - val_loss: 35.1645 - val_mae: 3.2650 - val_mse: 35.1645\n",
      "Epoch 931/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.6507 - mae: 3.3870 - mse: 36.6507 - val_loss: 36.3996 - val_mae: 3.3695 - val_mse: 36.3996\n",
      "Epoch 932/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7537 - mae: 3.3801 - mse: 36.7537 - val_loss: 38.4454 - val_mae: 3.7013 - val_mse: 38.4454\n",
      "Epoch 933/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4714 - mae: 3.3032 - mse: 36.4714 - val_loss: 39.5843 - val_mae: 3.7434 - val_mse: 39.5843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2624 - mae: 3.3860 - mse: 37.2624 - val_loss: 39.5714 - val_mae: 3.5660 - val_mse: 39.5714\n",
      "Epoch 935/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4809 - mae: 3.4155 - mse: 36.4809 - val_loss: 40.9367 - val_mae: 3.5081 - val_mse: 40.9367\n",
      "Epoch 936/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 35.7117 - mae: 3.3518 - mse: 35.7117 - val_loss: 34.9575 - val_mae: 3.3381 - val_mse: 34.9575\n",
      "Epoch 937/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9458 - mae: 3.3906 - mse: 36.9458 - val_loss: 63.6006 - val_mae: 5.3806 - val_mse: 63.6006\n",
      "Epoch 938/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4282 - mae: 3.3740 - mse: 36.4282 - val_loss: 39.1080 - val_mae: 3.4334 - val_mse: 39.1080\n",
      "Epoch 939/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.1952 - mae: 3.3561 - mse: 36.1952 - val_loss: 52.0579 - val_mae: 4.7385 - val_mse: 52.0579\n",
      "Epoch 940/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.5481 - mae: 3.4218 - mse: 37.5481 - val_loss: 40.4809 - val_mae: 3.4127 - val_mse: 40.4809\n",
      "Epoch 941/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.1292 - mae: 3.4120 - mse: 37.1292 - val_loss: 39.5033 - val_mae: 3.7390 - val_mse: 39.5033\n",
      "Epoch 942/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9265 - mae: 3.3471 - mse: 36.9265 - val_loss: 34.3899 - val_mae: 3.2508 - val_mse: 34.3899\n",
      "Epoch 943/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.4567 - mae: 3.4121 - mse: 37.4567 - val_loss: 36.8362 - val_mae: 3.2923 - val_mse: 36.8362\n",
      "Epoch 944/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1305 - mae: 3.3344 - mse: 37.1305 - val_loss: 43.0351 - val_mae: 3.7133 - val_mse: 43.0350\n",
      "Epoch 945/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9385 - mae: 3.3527 - mse: 36.9385 - val_loss: 42.2341 - val_mae: 3.3140 - val_mse: 42.2341\n",
      "Epoch 946/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.4664 - mae: 3.3599 - mse: 36.4664 - val_loss: 40.7580 - val_mae: 3.3946 - val_mse: 40.7580\n",
      "Epoch 947/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.8256 - mae: 3.3763 - mse: 36.8256 - val_loss: 38.9017 - val_mae: 3.5513 - val_mse: 38.9017\n",
      "Epoch 948/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0231 - mae: 3.3741 - mse: 38.0231 - val_loss: 40.3165 - val_mae: 3.3526 - val_mse: 40.3165\n",
      "Epoch 949/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6282 - mae: 3.3599 - mse: 37.6282 - val_loss: 44.6146 - val_mae: 4.7598 - val_mse: 44.6146\n",
      "Epoch 950/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.3959 - mae: 3.3108 - mse: 36.3959 - val_loss: 33.3717 - val_mae: 3.3255 - val_mse: 33.3717\n",
      "Epoch 951/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9744 - mae: 3.3776 - mse: 36.9744 - val_loss: 36.4809 - val_mae: 3.2844 - val_mse: 36.4809\n",
      "Epoch 952/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.3990 - mae: 3.3204 - mse: 36.3990 - val_loss: 36.5208 - val_mae: 3.5217 - val_mse: 36.5208\n",
      "Epoch 953/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.7455 - mae: 3.3453 - mse: 36.7455 - val_loss: 31.3954 - val_mae: 3.1698 - val_mse: 31.3954\n",
      "Epoch 954/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.0004 - mae: 3.3687 - mse: 37.0004 - val_loss: 39.5748 - val_mae: 3.5876 - val_mse: 39.5747\n",
      "Epoch 955/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.5408 - mae: 3.3316 - mse: 36.5408 - val_loss: 44.2419 - val_mae: 3.8065 - val_mse: 44.2419\n",
      "Epoch 956/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.3860 - mae: 3.4284 - mse: 36.3860 - val_loss: 40.2783 - val_mae: 3.9526 - val_mse: 40.2783\n",
      "Epoch 957/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.9834 - mae: 3.3890 - mse: 36.9833 - val_loss: 43.1685 - val_mae: 4.1082 - val_mse: 43.1685\n",
      "Epoch 958/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.3498 - mae: 3.4110 - mse: 38.3498 - val_loss: 52.6531 - val_mae: 4.1732 - val_mse: 52.6531\n",
      "Epoch 959/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 37.9221 - mae: 3.4107 - mse: 37.9221 - val_loss: 64.1850 - val_mae: 4.8693 - val_mse: 64.1850\n",
      "Epoch 960/1000\n",
      "3852/3852 [==============================] - 0s 38us/step - loss: 37.5887 - mae: 3.4176 - mse: 37.5887 - val_loss: 44.3888 - val_mae: 3.7095 - val_mse: 44.3888\n",
      "Epoch 961/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.1569 - mae: 3.3632 - mse: 36.1569 - val_loss: 37.9429 - val_mae: 3.4828 - val_mse: 37.9429\n",
      "Epoch 962/1000\n",
      "3852/3852 [==============================] - 0s 50us/step - loss: 36.3468 - mae: 3.3217 - mse: 36.3468 - val_loss: 39.4779 - val_mae: 3.4407 - val_mse: 39.4779\n",
      "Epoch 963/1000\n",
      "3852/3852 [==============================] - 0s 48us/step - loss: 37.4228 - mae: 3.3680 - mse: 37.4228 - val_loss: 37.1067 - val_mae: 3.3888 - val_mse: 37.1067\n",
      "Epoch 964/1000\n",
      "3852/3852 [==============================] - 0s 39us/step - loss: 36.0741 - mae: 3.3322 - mse: 36.0741 - val_loss: 38.0236 - val_mae: 3.4448 - val_mse: 38.0236\n",
      "Epoch 965/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 38.7077 - mae: 3.4151 - mse: 38.7077 - val_loss: 40.2269 - val_mae: 3.3460 - val_mse: 40.2269\n",
      "Epoch 966/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7657 - mae: 3.5008 - mse: 37.7657 - val_loss: 124.7947 - val_mae: 7.4694 - val_mse: 124.7947\n",
      "Epoch 967/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2271 - mae: 3.4289 - mse: 37.2271 - val_loss: 41.9341 - val_mae: 3.4300 - val_mse: 41.9341\n",
      "Epoch 968/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.4554 - mae: 3.3534 - mse: 36.4554 - val_loss: 42.6247 - val_mae: 3.5841 - val_mse: 42.6247\n",
      "Epoch 969/1000\n",
      "3852/3852 [==============================] - 0s 36us/step - loss: 36.9825 - mae: 3.3690 - mse: 36.9825 - val_loss: 55.3046 - val_mae: 4.3729 - val_mse: 55.3046\n",
      "Epoch 970/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2452 - mae: 3.4315 - mse: 38.2452 - val_loss: 40.9925 - val_mae: 3.3495 - val_mse: 40.9925\n",
      "Epoch 971/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 35.9467 - mae: 3.3264 - mse: 35.9467 - val_loss: 47.9438 - val_mae: 3.6425 - val_mse: 47.9438\n",
      "Epoch 972/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 36.9247 - mae: 3.3534 - mse: 36.9247 - val_loss: 40.9081 - val_mae: 3.3968 - val_mse: 40.9081\n",
      "Epoch 973/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.7223 - mae: 3.4561 - mse: 37.7223 - val_loss: 47.7559 - val_mae: 3.6204 - val_mse: 47.7559\n",
      "Epoch 974/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3115 - mae: 3.4426 - mse: 37.3115 - val_loss: 39.8868 - val_mae: 3.2405 - val_mse: 39.8868\n",
      "Epoch 975/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.0796 - mae: 3.3660 - mse: 37.0796 - val_loss: 36.3976 - val_mae: 3.3651 - val_mse: 36.3976\n",
      "Epoch 976/1000\n",
      "3852/3852 [==============================] - 0s 40us/step - loss: 38.2711 - mae: 3.4820 - mse: 38.2711 - val_loss: 71.4124 - val_mae: 4.6891 - val_mse: 71.4124\n",
      "Epoch 977/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0059 - mae: 3.4849 - mse: 38.0059 - val_loss: 36.0301 - val_mae: 3.3236 - val_mse: 36.0302\n",
      "Epoch 978/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2059 - mae: 3.4290 - mse: 38.2059 - val_loss: 50.9868 - val_mae: 4.6520 - val_mse: 50.9868\n",
      "Epoch 979/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.5626 - mae: 3.4349 - mse: 38.5625 - val_loss: 38.7753 - val_mae: 3.3626 - val_mse: 38.7753\n",
      "Epoch 980/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 39.6543 - mae: 3.5327 - mse: 39.6543 - val_loss: 40.1752 - val_mae: 3.3042 - val_mse: 40.1752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.4169 - mae: 3.4330 - mse: 39.4169 - val_loss: 59.8417 - val_mae: 4.1160 - val_mse: 59.8417\n",
      "Epoch 982/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.8180 - mae: 3.4947 - mse: 38.8180 - val_loss: 42.1979 - val_mae: 3.4618 - val_mse: 42.1979\n",
      "Epoch 983/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.9637 - mae: 3.4626 - mse: 37.9637 - val_loss: 63.6064 - val_mae: 4.4227 - val_mse: 63.6064\n",
      "Epoch 984/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 40.2399 - mae: 3.5410 - mse: 40.2399 - val_loss: 37.4125 - val_mae: 3.3733 - val_mse: 37.4125\n",
      "Epoch 985/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.1775 - mae: 3.3842 - mse: 37.1775 - val_loss: 40.4433 - val_mae: 3.6199 - val_mse: 40.4433\n",
      "Epoch 986/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.8244 - mae: 3.3940 - mse: 37.8244 - val_loss: 48.2459 - val_mae: 3.8920 - val_mse: 48.2459\n",
      "Epoch 987/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.3227 - mae: 3.4265 - mse: 37.3227 - val_loss: 37.4687 - val_mae: 3.3297 - val_mse: 37.4687\n",
      "Epoch 988/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 37.2332 - mae: 3.4042 - mse: 37.2332 - val_loss: 43.5140 - val_mae: 3.4001 - val_mse: 43.5140\n",
      "Epoch 989/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.2042 - mae: 3.3895 - mse: 37.2042 - val_loss: 40.8957 - val_mae: 3.4476 - val_mse: 40.8957\n",
      "Epoch 990/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.1308 - mae: 3.4000 - mse: 36.1309 - val_loss: 44.5038 - val_mae: 3.3544 - val_mse: 44.5038\n",
      "Epoch 991/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.0616 - mae: 3.4660 - mse: 38.0616 - val_loss: 54.5206 - val_mae: 4.4881 - val_mse: 54.5206\n",
      "Epoch 992/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.6559 - mae: 3.3872 - mse: 37.6559 - val_loss: 37.2578 - val_mae: 3.5506 - val_mse: 37.2578\n",
      "Epoch 993/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 39.2429 - mae: 3.4294 - mse: 39.2429 - val_loss: 41.6048 - val_mae: 3.5758 - val_mse: 41.6048\n",
      "Epoch 994/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.4384 - mae: 3.3476 - mse: 36.4384 - val_loss: 36.6130 - val_mae: 3.2748 - val_mse: 36.6130\n",
      "Epoch 995/1000\n",
      "3852/3852 [==============================] - 0s 33us/step - loss: 36.8637 - mae: 3.3635 - mse: 36.8637 - val_loss: 34.8113 - val_mae: 3.2824 - val_mse: 34.8113\n",
      "Epoch 996/1000\n",
      "3852/3852 [==============================] - 0s 35us/step - loss: 38.6536 - mae: 3.4775 - mse: 38.6536 - val_loss: 45.8091 - val_mae: 3.5144 - val_mse: 45.8091\n",
      "Epoch 997/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 37.7929 - mae: 3.4386 - mse: 37.7929 - val_loss: 46.1123 - val_mae: 3.5598 - val_mse: 46.1123\n",
      "Epoch 998/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2059 - mae: 3.5071 - mse: 38.2059 - val_loss: 42.6427 - val_mae: 3.3210 - val_mse: 42.6427\n",
      "Epoch 999/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 36.4921 - mae: 3.3686 - mse: 36.4921 - val_loss: 39.5650 - val_mae: 3.3119 - val_mse: 39.5650\n",
      "Epoch 1000/1000\n",
      "3852/3852 [==============================] - 0s 34us/step - loss: 38.2275 - mae: 3.3864 - mse: 38.2275 - val_loss: 38.3164 - val_mae: 3.2855 - val_mse: 38.3164\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "history = model.fit(\n",
    "  X_train, y_train,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>45.809096</td>\n",
       "      <td>3.514379</td>\n",
       "      <td>45.809090</td>\n",
       "      <td>38.653640</td>\n",
       "      <td>3.477527</td>\n",
       "      <td>38.653641</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>46.112265</td>\n",
       "      <td>3.559802</td>\n",
       "      <td>46.112263</td>\n",
       "      <td>37.792872</td>\n",
       "      <td>3.438610</td>\n",
       "      <td>37.792866</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>42.642742</td>\n",
       "      <td>3.321034</td>\n",
       "      <td>42.642738</td>\n",
       "      <td>38.205910</td>\n",
       "      <td>3.507082</td>\n",
       "      <td>38.205902</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>39.565006</td>\n",
       "      <td>3.311915</td>\n",
       "      <td>39.565006</td>\n",
       "      <td>36.492062</td>\n",
       "      <td>3.368576</td>\n",
       "      <td>36.492069</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>38.316401</td>\n",
       "      <td>3.285467</td>\n",
       "      <td>38.316406</td>\n",
       "      <td>38.227504</td>\n",
       "      <td>3.386400</td>\n",
       "      <td>38.227501</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      val_loss   val_mae    val_mse       loss       mae        mse  epoch\n",
       "995  45.809096  3.514379  45.809090  38.653640  3.477527  38.653641    995\n",
       "996  46.112265  3.559802  46.112263  37.792872  3.438610  37.792866    996\n",
       "997  42.642742  3.321034  42.642738  38.205910  3.507082  38.205902    997\n",
       "998  39.565006  3.311915  39.565006  36.492062  3.368576  36.492069    998\n",
       "999  38.316401  3.285467  38.316406  38.227504  3.386400  38.227501    999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/tensorflow/docs\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MAE [Prices]')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "plotter.plot({'Basic': history}, metric = \"mae\")\n",
    "plt.ylim([0, 10])\n",
    "plt.ylabel('MAE [Prices]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['Name'] = label_encoder.fit_transform(test['Name'])\n",
    "test['Location'] = label_encoder.fit_transform(test['Location'])\n",
    "test['Fuel_Type'] = label_encoder.fit_transform(test['Fuel_Type'])\n",
    "test['Transmission'] = label_encoder.fit_transform(test['Transmission'])\n",
    "test['Owner_Type'] = label_encoder.fit_transform(test['Owner_Type'])\n",
    "test_predictions = model.predict(test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsave=pd.read_excel('data_test.xlsx')\n",
    "testsave['Prices']=test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('testpredictions.xlsx', engine='xlsxwriter')\n",
    "testsave.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
